{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPANION WORKBOOK\n",
    "\n",
    "# Model Training\n",
    "\n",
    "To make the most out of this program, we strongly recommend you to:\n",
    "1. First practice writing and implementing all of the code from Coding Section of the online module.\n",
    "2. Then, freely experiment with and explore any interesting or confusing concepts. Simply insert new code cells and then use the help of Google and official documentation.\n",
    "3. Finally, tackle all of the exercises at the end. They will help you tie everything together and **learn in context.**\n",
    "\n",
    "#### <span style=\"color:#555\">MODULE CODE SANDBOX</span>\n",
    "\n",
    "Use this space to practice writing and implementing all of the code from Coding Section of the online module. Insert new code cells as needed, and feel free to write notes to yourself in Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Spending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Regularized Regression algos\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "\n",
    "# Import Tree Ensemble algos\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1863, 40)\n"
     ]
    }
   ],
   "source": [
    "# Load ABT from Module 3\n",
    "df = pd.read_csv('./project_files/analytical_base_table.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate object for target variable\n",
    "y = df.tx_price\n",
    "\n",
    "# Create separate object for input features\n",
    "X = df.drop('tx_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 373 1490 373\n"
     ]
    }
   ],
   "source": [
    "print( len(X_train), len(X_test), len(y_train), len(y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Preprocessing & Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.434228</td>\n",
       "      <td>2.579195</td>\n",
       "      <td>2322.785235</td>\n",
       "      <td>12746.659732</td>\n",
       "      <td>0.878523</td>\n",
       "      <td>39.495973</td>\n",
       "      <td>4.388591</td>\n",
       "      <td>5.004698</td>\n",
       "      <td>5.185906</td>\n",
       "      <td>39.561074</td>\n",
       "      <td>3.361745</td>\n",
       "      <td>22.909396</td>\n",
       "      <td>15.770470</td>\n",
       "      <td>38.508725</td>\n",
       "      <td>69.471141</td>\n",
       "      <td>65.012752</td>\n",
       "      <td>464.265772</td>\n",
       "      <td>139.610067</td>\n",
       "      <td>6.510067</td>\n",
       "      <td>2.779195</td>\n",
       "      <td>0.092617</td>\n",
       "      <td>24.343624</td>\n",
       "      <td>0.265772</td>\n",
       "      <td>17.940268</td>\n",
       "      <td>0.073154</td>\n",
       "      <td>0.643624</td>\n",
       "      <td>0.189262</td>\n",
       "      <td>0.060403</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.359732</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>0.059060</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>0.119463</td>\n",
       "      <td>0.037584</td>\n",
       "      <td>0.268456</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>0.419463</td>\n",
       "      <td>0.580537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.072914</td>\n",
       "      <td>0.930476</td>\n",
       "      <td>1297.101677</td>\n",
       "      <td>34805.545024</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>46.985862</td>\n",
       "      <td>4.498340</td>\n",
       "      <td>8.441995</td>\n",
       "      <td>7.442707</td>\n",
       "      <td>52.334853</td>\n",
       "      <td>4.693709</td>\n",
       "      <td>25.724463</td>\n",
       "      <td>17.999282</td>\n",
       "      <td>6.615223</td>\n",
       "      <td>19.865080</td>\n",
       "      <td>17.092542</td>\n",
       "      <td>227.249819</td>\n",
       "      <td>71.510905</td>\n",
       "      <td>1.975224</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>0.289993</td>\n",
       "      <td>21.209025</td>\n",
       "      <td>0.441892</td>\n",
       "      <td>6.452059</td>\n",
       "      <td>0.260477</td>\n",
       "      <td>0.479089</td>\n",
       "      <td>0.391848</td>\n",
       "      <td>0.238311</td>\n",
       "      <td>0.180146</td>\n",
       "      <td>0.480083</td>\n",
       "      <td>0.153601</td>\n",
       "      <td>0.235817</td>\n",
       "      <td>0.247966</td>\n",
       "      <td>0.324442</td>\n",
       "      <td>0.190252</td>\n",
       "      <td>0.443305</td>\n",
       "      <td>0.247966</td>\n",
       "      <td>0.493637</td>\n",
       "      <td>0.493637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1351.000000</td>\n",
       "      <td>1542.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1913.500000</td>\n",
       "      <td>6183.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>426.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3014.750000</td>\n",
       "      <td>11761.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7842.000000</td>\n",
       "      <td>436471.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4508.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              beds        baths         sqft       lot_size     basement  \\\n",
       "count  1490.000000  1490.000000  1490.000000    1490.000000  1490.000000   \n",
       "mean      3.434228     2.579195  2322.785235   12746.659732     0.878523   \n",
       "std       1.072914     0.930476  1297.101677   34805.545024     0.326790   \n",
       "min       1.000000     1.000000   500.000000       0.000000     0.000000   \n",
       "25%       3.000000     2.000000  1351.000000    1542.000000     1.000000   \n",
       "50%       4.000000     3.000000  1913.500000    6183.000000     1.000000   \n",
       "75%       4.000000     3.000000  3014.750000   11761.000000     1.000000   \n",
       "max       5.000000     6.000000  7842.000000  436471.000000     1.000000   \n",
       "\n",
       "       restaurants    groceries    nightlife        cafes     shopping  \\\n",
       "count  1490.000000  1490.000000  1490.000000  1490.000000  1490.000000   \n",
       "mean     39.495973     4.388591     5.004698     5.185906    39.561074   \n",
       "std      46.985862     4.498340     8.441995     7.442707    52.334853   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       6.000000     1.000000     0.000000     0.000000     6.000000   \n",
       "50%      21.000000     3.000000     2.000000     3.000000    20.000000   \n",
       "75%      56.000000     7.000000     6.000000     6.000000    50.000000   \n",
       "max     266.000000    24.000000    53.000000    47.000000   340.000000   \n",
       "\n",
       "       arts_entertainment  beauty_spas  active_life   median_age      married  \\\n",
       "count         1490.000000  1490.000000  1490.000000  1490.000000  1490.000000   \n",
       "mean             3.361745    22.909396    15.770470    38.508725    69.471141   \n",
       "std              4.693709    25.724463    17.999282     6.615223    19.865080   \n",
       "min              0.000000     0.000000     0.000000    22.000000    11.000000   \n",
       "25%              0.000000     4.000000     4.000000    33.000000    59.000000   \n",
       "50%              2.000000    15.000000    10.000000    38.000000    74.000000   \n",
       "75%              5.000000    35.000000    21.000000    43.000000    84.000000   \n",
       "max             35.000000   177.000000    94.000000    69.000000   100.000000   \n",
       "\n",
       "       college_grad  property_tax    insurance  median_school  num_schools  \\\n",
       "count   1490.000000   1490.000000  1490.000000    1490.000000  1490.000000   \n",
       "mean      65.012752    464.265772   139.610067       6.510067     2.779195   \n",
       "std       17.092542    227.249819    71.510905       1.975224     0.517235   \n",
       "min        5.000000     88.000000    30.000000       1.000000     1.000000   \n",
       "25%       53.250000    321.000000    94.000000       5.000000     3.000000   \n",
       "50%       66.000000    426.000000   125.000000       7.000000     3.000000   \n",
       "75%       78.000000    572.000000   169.000000       8.000000     3.000000   \n",
       "max      100.000000   4508.000000  1374.000000      10.000000     4.000000   \n",
       "\n",
       "       two_and_two  property_age  during_recession  school_score  \\\n",
       "count  1490.000000   1490.000000       1490.000000   1490.000000   \n",
       "mean      0.092617     24.343624          0.265772     17.940268   \n",
       "std       0.289993     21.209025          0.441892      6.452059   \n",
       "min       0.000000      0.000000          0.000000      3.000000   \n",
       "25%       0.000000      6.000000          0.000000     12.000000   \n",
       "50%       0.000000     20.000000          0.000000     18.000000   \n",
       "75%       0.000000     38.000000          1.000000     24.000000   \n",
       "max       1.000000    114.000000          1.000000     30.000000   \n",
       "\n",
       "       roof_Asphalt  roof_Composition Shingle  roof_Missing   roof_Other  \\\n",
       "count   1490.000000               1490.000000   1490.000000  1490.000000   \n",
       "mean       0.073154                  0.643624      0.189262     0.060403   \n",
       "std        0.260477                  0.479089      0.391848     0.238311   \n",
       "min        0.000000                  0.000000      0.000000     0.000000   \n",
       "25%        0.000000                  0.000000      0.000000     0.000000   \n",
       "50%        0.000000                  1.000000      0.000000     0.000000   \n",
       "75%        0.000000                  1.000000      0.000000     0.000000   \n",
       "max        1.000000                  1.000000      1.000000     1.000000   \n",
       "\n",
       "       roof_Shake Shingle  exterior_walls_Brick  exterior_walls_Brick veneer  \\\n",
       "count         1490.000000           1490.000000                  1490.000000   \n",
       "mean             0.033557              0.359732                     0.024161   \n",
       "std              0.180146              0.480083                     0.153601   \n",
       "min              0.000000              0.000000                     0.000000   \n",
       "25%              0.000000              0.000000                     0.000000   \n",
       "50%              0.000000              0.000000                     0.000000   \n",
       "75%              0.000000              1.000000                     0.000000   \n",
       "max              1.000000              1.000000                     1.000000   \n",
       "\n",
       "       exterior_walls_Combination  exterior_walls_Metal  \\\n",
       "count                 1490.000000           1490.000000   \n",
       "mean                     0.059060              0.065772   \n",
       "std                      0.235817              0.247966   \n",
       "min                      0.000000              0.000000   \n",
       "25%                      0.000000              0.000000   \n",
       "50%                      0.000000              0.000000   \n",
       "75%                      0.000000              0.000000   \n",
       "max                      1.000000              1.000000   \n",
       "\n",
       "       exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count             1490.000000           1490.000000   \n",
       "mean                 0.119463              0.037584   \n",
       "std                  0.324442              0.190252   \n",
       "min                  0.000000              0.000000   \n",
       "25%                  0.000000              0.000000   \n",
       "50%                  0.000000              0.000000   \n",
       "75%                  0.000000              0.000000   \n",
       "max                  1.000000              1.000000   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  \\\n",
       "count                         1490.000000          1490.000000   \n",
       "mean                             0.268456             0.065772   \n",
       "std                              0.443305             0.247966   \n",
       "min                              0.000000             0.000000   \n",
       "25%                              0.000000             0.000000   \n",
       "50%                              0.000000             0.000000   \n",
       "75%                              1.000000             0.000000   \n",
       "max                              1.000000             1.000000   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                  1490.000000   \n",
       "mean                                      0.419463   \n",
       "std                                       0.493637   \n",
       "min                                       0.000000   \n",
       "25%                                       0.000000   \n",
       "50%                                       0.000000   \n",
       "75%                                       1.000000   \n",
       "max                                       1.000000   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                  1490.000000  \n",
       "mean                      0.580537  \n",
       "std                       0.493637  \n",
       "min                       0.000000  \n",
       "25%                       0.000000  \n",
       "50%                       1.000000  \n",
       "75%                       1.000000  \n",
       "max                       1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summay statistics of X_train \n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize X_train\n",
    "X_train_new = (X_train - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1.490000e+03</td>\n",
       "      <td>1490.00000</td>\n",
       "      <td>1490.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-7.212724e-17</td>\n",
       "      <td>-1.680982e-16</td>\n",
       "      <td>6.914678e-17</td>\n",
       "      <td>-4.768743e-18</td>\n",
       "      <td>1.382936e-16</td>\n",
       "      <td>-2.384372e-17</td>\n",
       "      <td>1.144498e-16</td>\n",
       "      <td>-4.768743e-18</td>\n",
       "      <td>2.861246e-17</td>\n",
       "      <td>-9.537486e-18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.199366e-17</td>\n",
       "      <td>1.430623e-17</td>\n",
       "      <td>-3.290433e-16</td>\n",
       "      <td>-1.931341e-16</td>\n",
       "      <td>-5.960929e-17</td>\n",
       "      <td>1.007397e-16</td>\n",
       "      <td>-7.331943e-17</td>\n",
       "      <td>1.573685e-16</td>\n",
       "      <td>2.181700e-16</td>\n",
       "      <td>-2.384372e-18</td>\n",
       "      <td>-4.291869e-17</td>\n",
       "      <td>1.967107e-17</td>\n",
       "      <td>-1.478310e-16</td>\n",
       "      <td>-8.047254e-18</td>\n",
       "      <td>2.980464e-17</td>\n",
       "      <td>-1.669060e-17</td>\n",
       "      <td>-4.768743e-17</td>\n",
       "      <td>7.153115e-17</td>\n",
       "      <td>-2.145934e-17</td>\n",
       "      <td>2.443981e-17</td>\n",
       "      <td>-5.245618e-17</td>\n",
       "      <td>2.861246e-17</td>\n",
       "      <td>-2.384372e-17</td>\n",
       "      <td>3.993822e-17</td>\n",
       "      <td>-2.026716e-17</td>\n",
       "      <td>5.782101e-17</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.268801e+00</td>\n",
       "      <td>-1.697190e+00</td>\n",
       "      <td>-1.405276e+00</td>\n",
       "      <td>-3.662250e-01</td>\n",
       "      <td>-2.688343e+00</td>\n",
       "      <td>-8.405927e-01</td>\n",
       "      <td>-9.756023e-01</td>\n",
       "      <td>-5.928336e-01</td>\n",
       "      <td>-6.967768e-01</td>\n",
       "      <td>-7.559221e-01</td>\n",
       "      <td>-0.716224</td>\n",
       "      <td>-8.905685e-01</td>\n",
       "      <td>-8.761722e-01</td>\n",
       "      <td>-2.495566e+00</td>\n",
       "      <td>-2.943413e+00</td>\n",
       "      <td>-3.511049e+00</td>\n",
       "      <td>-1.655736e+00</td>\n",
       "      <td>-1.532774e+00</td>\n",
       "      <td>-2.789591e+00</td>\n",
       "      <td>-3.439819e+00</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-1.147796e+00</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-2.315581e+00</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>-1.343434e+00</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-0.84974</td>\n",
       "      <td>-1.17604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.047185e-01</td>\n",
       "      <td>-6.224713e-01</td>\n",
       "      <td>-7.491974e-01</td>\n",
       "      <td>-3.219217e-01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>-7.128947e-01</td>\n",
       "      <td>-7.532980e-01</td>\n",
       "      <td>-5.928336e-01</td>\n",
       "      <td>-6.967768e-01</td>\n",
       "      <td>-6.412758e-01</td>\n",
       "      <td>-0.716224</td>\n",
       "      <td>-7.350745e-01</td>\n",
       "      <td>-6.539411e-01</td>\n",
       "      <td>-8.327346e-01</td>\n",
       "      <td>-5.271130e-01</td>\n",
       "      <td>-6.881804e-01</td>\n",
       "      <td>-6.304329e-01</td>\n",
       "      <td>-6.378058e-01</td>\n",
       "      <td>-7.645042e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-8.648971e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>-9.206779e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>-1.343434e+00</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-0.84974</td>\n",
       "      <td>-1.17604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.273226e-01</td>\n",
       "      <td>4.522474e-01</td>\n",
       "      <td>-3.155383e-01</td>\n",
       "      <td>-1.885809e-01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>-3.936498e-01</td>\n",
       "      <td>-3.086896e-01</td>\n",
       "      <td>-3.559228e-01</td>\n",
       "      <td>-2.936977e-01</td>\n",
       "      <td>-3.737676e-01</td>\n",
       "      <td>-0.290121</td>\n",
       "      <td>-3.074659e-01</td>\n",
       "      <td>-3.205944e-01</td>\n",
       "      <td>-7.690215e-02</td>\n",
       "      <td>2.279809e-01</td>\n",
       "      <td>5.775901e-02</td>\n",
       "      <td>-1.683864e-01</td>\n",
       "      <td>-2.043054e-01</td>\n",
       "      <td>2.480391e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>-2.048007e-01</td>\n",
       "      <td>-6.014412e-01</td>\n",
       "      <td>9.257749e-03</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>-7.493115e-01</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>-6.055792e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-0.84974</td>\n",
       "      <td>0.84974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.273226e-01</td>\n",
       "      <td>4.522474e-01</td>\n",
       "      <td>5.334699e-01</td>\n",
       "      <td>-2.831904e-02</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>3.512552e-01</td>\n",
       "      <td>5.805274e-01</td>\n",
       "      <td>1.178989e-01</td>\n",
       "      <td>1.093814e-01</td>\n",
       "      <td>1.994641e-01</td>\n",
       "      <td>0.349032</td>\n",
       "      <td>4.700041e-01</td>\n",
       "      <td>2.905410e-01</td>\n",
       "      <td>6.789303e-01</td>\n",
       "      <td>7.313768e-01</td>\n",
       "      <td>7.598196e-01</td>\n",
       "      <td>4.740784e-01</td>\n",
       "      <td>4.109853e-01</td>\n",
       "      <td>7.543108e-01</td>\n",
       "      <td>4.268957e-01</td>\n",
       "      <td>-3.193783e-01</td>\n",
       "      <td>6.438946e-01</td>\n",
       "      <td>1.661557e+00</td>\n",
       "      <td>9.391934e-01</td>\n",
       "      <td>-2.808475e-01</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>-4.829980e-01</td>\n",
       "      <td>-2.534612e-01</td>\n",
       "      <td>-1.862765e-01</td>\n",
       "      <td>1.333663e+00</td>\n",
       "      <td>-1.572980e-01</td>\n",
       "      <td>-2.504503e-01</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>-3.682115e-01</td>\n",
       "      <td>-1.975485e-01</td>\n",
       "      <td>1.650203e+00</td>\n",
       "      <td>-2.652453e-01</td>\n",
       "      <td>1.17604</td>\n",
       "      <td>0.84974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459364e+00</td>\n",
       "      <td>3.676403e+00</td>\n",
       "      <td>4.255036e+00</td>\n",
       "      <td>1.217405e+01</td>\n",
       "      <td>3.717266e-01</td>\n",
       "      <td>4.820685e+00</td>\n",
       "      <td>4.359699e+00</td>\n",
       "      <td>5.685304e+00</td>\n",
       "      <td>5.618130e+00</td>\n",
       "      <td>5.740705e+00</td>\n",
       "      <td>6.740566</td>\n",
       "      <td>5.990042e+00</td>\n",
       "      <td>4.346258e+00</td>\n",
       "      <td>4.609259e+00</td>\n",
       "      <td>1.536810e+00</td>\n",
       "      <td>2.046931e+00</td>\n",
       "      <td>1.779422e+01</td>\n",
       "      <td>1.726156e+01</td>\n",
       "      <td>1.766854e+00</td>\n",
       "      <td>2.360253e+00</td>\n",
       "      <td>3.128982e+00</td>\n",
       "      <td>4.227275e+00</td>\n",
       "      <td>1.661557e+00</td>\n",
       "      <td>1.869129e+00</td>\n",
       "      <td>3.558261e+00</td>\n",
       "      <td>7.438617e-01</td>\n",
       "      <td>2.069013e+00</td>\n",
       "      <td>3.942729e+00</td>\n",
       "      <td>5.364762e+00</td>\n",
       "      <td>1.333663e+00</td>\n",
       "      <td>6.353092e+00</td>\n",
       "      <td>3.990129e+00</td>\n",
       "      <td>3.767565e+00</td>\n",
       "      <td>2.714008e+00</td>\n",
       "      <td>5.058652e+00</td>\n",
       "      <td>1.650203e+00</td>\n",
       "      <td>3.767565e+00</td>\n",
       "      <td>1.17604</td>\n",
       "      <td>0.84974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               beds         baths          sqft      lot_size      basement  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean  -7.212724e-17 -1.680982e-16  6.914678e-17 -4.768743e-18  1.382936e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.268801e+00 -1.697190e+00 -1.405276e+00 -3.662250e-01 -2.688343e+00   \n",
       "25%   -4.047185e-01 -6.224713e-01 -7.491974e-01 -3.219217e-01  3.717266e-01   \n",
       "50%    5.273226e-01  4.522474e-01 -3.155383e-01 -1.885809e-01  3.717266e-01   \n",
       "75%    5.273226e-01  4.522474e-01  5.334699e-01 -2.831904e-02  3.717266e-01   \n",
       "max    1.459364e+00  3.676403e+00  4.255036e+00  1.217405e+01  3.717266e-01   \n",
       "\n",
       "        restaurants     groceries     nightlife         cafes      shopping  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean  -2.384372e-17  1.144498e-16 -4.768743e-18  2.861246e-17 -9.537486e-18   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -8.405927e-01 -9.756023e-01 -5.928336e-01 -6.967768e-01 -7.559221e-01   \n",
       "25%   -7.128947e-01 -7.532980e-01 -5.928336e-01 -6.967768e-01 -6.412758e-01   \n",
       "50%   -3.936498e-01 -3.086896e-01 -3.559228e-01 -2.936977e-01 -3.737676e-01   \n",
       "75%    3.512552e-01  5.805274e-01  1.178989e-01  1.093814e-01  1.994641e-01   \n",
       "max    4.820685e+00  4.359699e+00  5.685304e+00  5.618130e+00  5.740705e+00   \n",
       "\n",
       "       arts_entertainment   beauty_spas   active_life    median_age  \\\n",
       "count         1490.000000  1.490000e+03  1.490000e+03  1.490000e+03   \n",
       "mean             0.000000 -6.199366e-17  1.430623e-17 -3.290433e-16   \n",
       "std              1.000000  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min             -0.716224 -8.905685e-01 -8.761722e-01 -2.495566e+00   \n",
       "25%             -0.716224 -7.350745e-01 -6.539411e-01 -8.327346e-01   \n",
       "50%             -0.290121 -3.074659e-01 -3.205944e-01 -7.690215e-02   \n",
       "75%              0.349032  4.700041e-01  2.905410e-01  6.789303e-01   \n",
       "max              6.740566  5.990042e+00  4.346258e+00  4.609259e+00   \n",
       "\n",
       "            married  college_grad  property_tax     insurance  median_school  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03  1.490000e+03   1.490000e+03   \n",
       "mean  -1.931341e-16 -5.960929e-17  1.007397e-16 -7.331943e-17   1.573685e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   1.000000e+00   \n",
       "min   -2.943413e+00 -3.511049e+00 -1.655736e+00 -1.532774e+00  -2.789591e+00   \n",
       "25%   -5.271130e-01 -6.881804e-01 -6.304329e-01 -6.378058e-01  -7.645042e-01   \n",
       "50%    2.279809e-01  5.775901e-02 -1.683864e-01 -2.043054e-01   2.480391e-01   \n",
       "75%    7.313768e-01  7.598196e-01  4.740784e-01  4.109853e-01   7.543108e-01   \n",
       "max    1.536810e+00  2.046931e+00  1.779422e+01  1.726156e+01   1.766854e+00   \n",
       "\n",
       "        num_schools   two_and_two  property_age  during_recession  \\\n",
       "count  1.490000e+03  1.490000e+03  1.490000e+03      1.490000e+03   \n",
       "mean   2.181700e-16 -2.384372e-18 -4.291869e-17      1.967107e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00      1.000000e+00   \n",
       "min   -3.439819e+00 -3.193783e-01 -1.147796e+00     -6.014412e-01   \n",
       "25%    4.268957e-01 -3.193783e-01 -8.648971e-01     -6.014412e-01   \n",
       "50%    4.268957e-01 -3.193783e-01 -2.048007e-01     -6.014412e-01   \n",
       "75%    4.268957e-01 -3.193783e-01  6.438946e-01      1.661557e+00   \n",
       "max    2.360253e+00  3.128982e+00  4.227275e+00      1.661557e+00   \n",
       "\n",
       "       school_score  roof_Asphalt  roof_Composition Shingle  roof_Missing  \\\n",
       "count  1.490000e+03  1.490000e+03              1.490000e+03  1.490000e+03   \n",
       "mean  -1.478310e-16 -8.047254e-18              2.980464e-17 -1.669060e-17   \n",
       "std    1.000000e+00  1.000000e+00              1.000000e+00  1.000000e+00   \n",
       "min   -2.315581e+00 -2.808475e-01             -1.343434e+00 -4.829980e-01   \n",
       "25%   -9.206779e-01 -2.808475e-01             -1.343434e+00 -4.829980e-01   \n",
       "50%    9.257749e-03 -2.808475e-01              7.438617e-01 -4.829980e-01   \n",
       "75%    9.391934e-01 -2.808475e-01              7.438617e-01 -4.829980e-01   \n",
       "max    1.869129e+00  3.558261e+00              7.438617e-01  2.069013e+00   \n",
       "\n",
       "         roof_Other  roof_Shake Shingle  exterior_walls_Brick  \\\n",
       "count  1.490000e+03        1.490000e+03          1.490000e+03   \n",
       "mean  -4.768743e-17        7.153115e-17         -2.145934e-17   \n",
       "std    1.000000e+00        1.000000e+00          1.000000e+00   \n",
       "min   -2.534612e-01       -1.862765e-01         -7.493115e-01   \n",
       "25%   -2.534612e-01       -1.862765e-01         -7.493115e-01   \n",
       "50%   -2.534612e-01       -1.862765e-01         -7.493115e-01   \n",
       "75%   -2.534612e-01       -1.862765e-01          1.333663e+00   \n",
       "max    3.942729e+00        5.364762e+00          1.333663e+00   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                 1.490000e+03                1.490000e+03   \n",
       "mean                  2.443981e-17               -5.245618e-17   \n",
       "std                   1.000000e+00                1.000000e+00   \n",
       "min                  -1.572980e-01               -2.504503e-01   \n",
       "25%                  -1.572980e-01               -2.504503e-01   \n",
       "50%                  -1.572980e-01               -2.504503e-01   \n",
       "75%                  -1.572980e-01               -2.504503e-01   \n",
       "max                   6.353092e+00                3.990129e+00   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count          1.490000e+03            1.490000e+03          1.490000e+03   \n",
       "mean           2.861246e-17           -2.384372e-17          3.993822e-17   \n",
       "std            1.000000e+00            1.000000e+00          1.000000e+00   \n",
       "min           -2.652453e-01           -3.682115e-01         -1.975485e-01   \n",
       "25%           -2.652453e-01           -3.682115e-01         -1.975485e-01   \n",
       "50%           -2.652453e-01           -3.682115e-01         -1.975485e-01   \n",
       "75%           -2.652453e-01           -3.682115e-01         -1.975485e-01   \n",
       "max            3.767565e+00            2.714008e+00          5.058652e+00   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  \\\n",
       "count                        1.490000e+03         1.490000e+03   \n",
       "mean                        -2.026716e-17         5.782101e-17   \n",
       "std                          1.000000e+00         1.000000e+00   \n",
       "min                         -6.055792e-01        -2.652453e-01   \n",
       "25%                         -6.055792e-01        -2.652453e-01   \n",
       "50%                         -6.055792e-01        -2.652453e-01   \n",
       "75%                          1.650203e+00        -2.652453e-01   \n",
       "max                          1.650203e+00         3.767565e+00   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                   1490.00000   \n",
       "mean                                       0.00000   \n",
       "std                                        1.00000   \n",
       "min                                       -0.84974   \n",
       "25%                                       -0.84974   \n",
       "50%                                       -0.84974   \n",
       "75%                                        1.17604   \n",
       "max                                        1.17604   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                   1490.00000  \n",
       "mean                       0.00000  \n",
       "std                        1.00000  \n",
       "min                       -1.17604  \n",
       "25%                       -1.17604  \n",
       "50%                        0.84974  \n",
       "75%                        0.84974  \n",
       "max                        0.84974  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train_new\n",
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-2.496</td>\n",
       "      <td>-2.943</td>\n",
       "      <td>-3.511</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.255</td>\n",
       "      <td>12.174</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>4.360</td>\n",
       "      <td>5.685</td>\n",
       "      <td>5.618</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.990</td>\n",
       "      <td>4.346</td>\n",
       "      <td>4.609</td>\n",
       "      <td>1.537</td>\n",
       "      <td>2.047</td>\n",
       "      <td>17.794</td>\n",
       "      <td>17.262</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>4.227</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 1490.000 1490.000 1490.000  1490.000  1490.000     1490.000   1490.000   \n",
       "mean    -0.000   -0.000    0.000    -0.000     0.000       -0.000      0.000   \n",
       "std      1.000    1.000    1.000     1.000     1.000        1.000      1.000   \n",
       "min     -2.269   -1.697   -1.405    -0.366    -2.688       -0.841     -0.976   \n",
       "25%     -0.405   -0.622   -0.749    -0.322     0.372       -0.713     -0.753   \n",
       "50%      0.527    0.452   -0.316    -0.189     0.372       -0.394     -0.309   \n",
       "75%      0.527    0.452    0.533    -0.028     0.372        0.351      0.581   \n",
       "max      1.459    3.676    4.255    12.174     0.372        4.821      4.360   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1490.000 1490.000  1490.000            1490.000     1490.000   \n",
       "mean      -0.000    0.000    -0.000               0.000       -0.000   \n",
       "std        1.000    1.000     1.000               1.000        1.000   \n",
       "min       -0.593   -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.593   -0.697    -0.641              -0.716       -0.735   \n",
       "50%       -0.356   -0.294    -0.374              -0.290       -0.307   \n",
       "75%        0.118    0.109     0.199               0.349        0.470   \n",
       "max        5.685    5.618     5.741               6.741        5.990   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1490.000    1490.000 1490.000      1490.000      1490.000   \n",
       "mean         0.000      -0.000   -0.000        -0.000         0.000   \n",
       "std          1.000       1.000    1.000         1.000         1.000   \n",
       "min         -0.876      -2.496   -2.943        -3.511        -1.656   \n",
       "25%         -0.654      -0.833   -0.527        -0.688        -0.630   \n",
       "50%         -0.321      -0.077    0.228         0.058        -0.168   \n",
       "75%          0.291       0.679    0.731         0.760         0.474   \n",
       "max          4.346       4.609    1.537         2.047        17.794   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  property_age  \\\n",
       "count   1490.000       1490.000     1490.000     1490.000      1490.000   \n",
       "mean      -0.000          0.000        0.000       -0.000        -0.000   \n",
       "std        1.000          1.000        1.000        1.000         1.000   \n",
       "min       -1.533         -2.790       -3.440       -0.319        -1.148   \n",
       "25%       -0.638         -0.765        0.427       -0.319        -0.865   \n",
       "50%       -0.204          0.248        0.427       -0.319        -0.205   \n",
       "75%        0.411          0.754        0.427       -0.319         0.644   \n",
       "max       17.262          1.767        2.360        3.129         4.227   \n",
       "\n",
       "       during_recession  school_score  roof_Asphalt  roof_Composition Shingle  \\\n",
       "count          1490.000      1490.000      1490.000                  1490.000   \n",
       "mean              0.000        -0.000        -0.000                     0.000   \n",
       "std               1.000         1.000         1.000                     1.000   \n",
       "min              -0.601        -2.316        -0.281                    -1.343   \n",
       "25%              -0.601        -0.921        -0.281                    -1.343   \n",
       "50%              -0.601         0.009        -0.281                     0.744   \n",
       "75%               1.662         0.939        -0.281                     0.744   \n",
       "max               1.662         1.869         3.558                     0.744   \n",
       "\n",
       "       roof_Missing  roof_Other  roof_Shake Shingle  exterior_walls_Brick  \\\n",
       "count      1490.000    1490.000            1490.000              1490.000   \n",
       "mean         -0.000      -0.000               0.000                -0.000   \n",
       "std           1.000       1.000               1.000                 1.000   \n",
       "min          -0.483      -0.253              -0.186                -0.749   \n",
       "25%          -0.483      -0.253              -0.186                -0.749   \n",
       "50%          -0.483      -0.253              -0.186                -0.749   \n",
       "75%          -0.483      -0.253              -0.186                 1.334   \n",
       "max           2.069       3.943               5.365                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1490.000                    1490.000   \n",
       "mean                         0.000                      -0.000   \n",
       "std                          1.000                       1.000   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1490.000                1490.000              1490.000   \n",
       "mean                  0.000                  -0.000                 0.000   \n",
       "std                   1.000                   1.000                 1.000   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  \\\n",
       "count                            1490.000             1490.000   \n",
       "mean                               -0.000                0.000   \n",
       "std                                 1.000                1.000   \n",
       "min                                -0.606               -0.265   \n",
       "25%                                -0.606               -0.265   \n",
       "50%                                -0.606               -0.265   \n",
       "75%                                 1.650               -0.265   \n",
       "max                                 1.650                3.768   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                     1490.000   \n",
       "mean                                         0.000   \n",
       "std                                          1.000   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1490.000  \n",
       "mean                         0.000  \n",
       "std                          1.000  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train_new\n",
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRONG WAY!\n",
    "X_test_new = (X_test - X_test.mean()) / X_test.std()\n",
    "\n",
    "# Correct way!\n",
    "X_test_new = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.121</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.853</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.991</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-1.740</td>\n",
       "      <td>-2.843</td>\n",
       "      <td>-2.692</td>\n",
       "      <td>-1.396</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.128</td>\n",
       "      <td>12.149</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>3.915</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.349</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.912</td>\n",
       "      <td>4.013</td>\n",
       "      <td>4.156</td>\n",
       "      <td>1.537</td>\n",
       "      <td>1.988</td>\n",
       "      <td>4.791</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>3.284</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beds   baths    sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 373.000 373.000 373.000   373.000   373.000      373.000    373.000   \n",
       "mean   -0.117  -0.081  -0.091    -0.032     0.011        0.091      0.141   \n",
       "std     0.959   0.989   1.002     1.034     0.988        1.004      0.996   \n",
       "min    -2.269  -1.697  -1.261    -0.366    -2.688       -0.841     -0.976   \n",
       "25%    -0.405  -0.622  -0.804    -0.325     0.372       -0.628     -0.753   \n",
       "50%    -0.405  -0.622  -0.387    -0.266     0.372       -0.287     -0.086   \n",
       "75%     0.527   0.452   0.306    -0.063     0.372        0.500      0.581   \n",
       "max     1.459   3.676   4.128    12.149     0.372        4.821      3.915   \n",
       "\n",
       "       nightlife   cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count    373.000 373.000   373.000             373.000      373.000   \n",
       "mean       0.057   0.109     0.132               0.048        0.108   \n",
       "std        1.034   1.078     1.121               1.013        1.019   \n",
       "min       -0.593  -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.474  -0.562    -0.565              -0.716       -0.657   \n",
       "50%       -0.356  -0.294    -0.259              -0.290       -0.230   \n",
       "75%        0.118   0.244     0.333               0.349        0.587   \n",
       "max        5.804   5.349     5.741               6.741        5.912   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count      373.000     373.000  373.000       373.000       373.000   \n",
       "mean         0.035       0.072   -0.101         0.010        -0.064   \n",
       "std          0.922       1.021    0.949         0.945         0.890   \n",
       "min         -0.876      -1.740   -2.843        -2.692        -1.396   \n",
       "25%         -0.543      -0.682   -0.678        -0.703        -0.652   \n",
       "50%         -0.265      -0.077    0.077         0.058        -0.243   \n",
       "75%          0.346       0.679    0.631         0.760         0.267   \n",
       "max          4.013       4.156    1.537         1.988         4.791   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  property_age  \\\n",
       "count    373.000        373.000      373.000      373.000       373.000   \n",
       "mean      -0.055         -0.036        0.121        0.050         0.013   \n",
       "std        0.908          1.043        0.895        1.068         0.972   \n",
       "min       -1.295         -2.790       -3.440       -0.319        -1.148   \n",
       "25%       -0.666         -0.765        0.427       -0.319        -0.912   \n",
       "50%       -0.246          0.248        0.427       -0.319        -0.158   \n",
       "75%        0.271          0.754        0.427       -0.319         0.691   \n",
       "max        5.375          1.767        2.360        3.129         3.284   \n",
       "\n",
       "       during_recession  school_score  roof_Asphalt  roof_Composition Shingle  \\\n",
       "count           373.000       373.000       373.000                   373.000   \n",
       "mean             -0.025         0.033        -0.003                     0.011   \n",
       "std               0.987         1.011         0.996                     0.998   \n",
       "min              -0.601        -2.316        -0.281                    -1.343   \n",
       "25%              -0.601        -0.921        -0.281                    -1.343   \n",
       "50%              -0.601         0.009        -0.281                     0.744   \n",
       "75%               1.662         0.939        -0.281                     0.744   \n",
       "max               1.662         1.869         3.558                     0.744   \n",
       "\n",
       "       roof_Missing  roof_Other  roof_Shake Shingle  exterior_walls_Brick  \\\n",
       "count       373.000     373.000             373.000               373.000   \n",
       "mean         -0.004       0.028              -0.052                 0.066   \n",
       "std           0.998       1.051               0.853                 1.018   \n",
       "min          -0.483      -0.253              -0.186                -0.749   \n",
       "25%          -0.483      -0.253              -0.186                -0.749   \n",
       "50%          -0.483      -0.253              -0.186                -0.749   \n",
       "75%          -0.483      -0.253              -0.186                 1.334   \n",
       "max           2.069       3.943               5.365                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                      373.000                     373.000   \n",
       "mean                         0.052                      -0.046   \n",
       "std                          1.150                       0.910   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count               373.000                 373.000               373.000   \n",
       "mean                 -0.027                  -0.005                -0.043   \n",
       "std                   0.951                   0.996                 0.890   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  \\\n",
       "count                             373.000              373.000   \n",
       "mean                               -0.025               -0.006   \n",
       "std                                 0.988                0.991   \n",
       "min                                -0.606               -0.265   \n",
       "25%                                -0.606               -0.265   \n",
       "50%                                -0.606               -0.265   \n",
       "75%                                 1.650               -0.265   \n",
       "max                                 1.650                3.768   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                      373.000   \n",
       "mean                                         0.112   \n",
       "std                                          1.013   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                      373.000  \n",
       "mean                        -0.112  \n",
       "std                          1.013  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For standardization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('lasso',\n",
       "                 Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=1000, normalize=False, positive=False,\n",
       "                       precompute=False, random_state=123, selection='cyclic',\n",
       "                       tol=0.0001, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline with Standardization and Lasso Regression\n",
    "make_pipeline(StandardScaler(), Lasso(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines dictionary\n",
    "pipelines = {\n",
    "    'lasso': make_pipeline(StandardScaler(), Lasso(random_state= 123)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state=123))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a pipeline for Elastic-Net\n",
    "pipelines['enet'] = make_pipeline(StandardScaler(), ElasticNet(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "         normalize=False, positive=False, precompute=False, random_state=123,\n",
       "         selection='cyclic', tol=0.0001, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "       normalize=False, positive=False, precompute=False, random_state=123,\n",
       "       selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'lasso__alpha': 1.0,\n",
       " 'lasso__copy_X': True,\n",
       " 'lasso__fit_intercept': True,\n",
       " 'lasso__max_iter': 1000,\n",
       " 'lasso__normalize': False,\n",
       " 'lasso__positive': False,\n",
       " 'lasso__precompute': False,\n",
       " 'lasso__random_state': 123,\n",
       " 'lasso__selection': 'cyclic',\n",
       " 'lasso__tol': 0.0001,\n",
       " 'lasso__warm_start': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List tuneable hyperparameters of our Lasso pipeline\n",
    "pipelines['lasso'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso hyperparameters\n",
    "lasso__hyperparameters = {\n",
    "    'lasso__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "# Ridge hyperparameters\n",
    "ridge__hyperparameters = {\n",
    "    'ridge__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net hyperparameters\n",
    "enet__hyperparameters = {\n",
    "    'elasticnet__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    'elasticnet__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creare hyperparameters dictionary\n",
    "hyperparameters = {\n",
    "    'lasso' : lasso__hyperparameters,\n",
    "    'ridge' : ridge__hyperparameters,\n",
    "    'enet' : enet__hyperparameters\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for cross-validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross-validation object from Lasso pipeline and Lasso hyperparameters\n",
    "model = GridSearchCV(pipelines['lasso'], hyperparameters['lasso'], cv=10, n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore ConvergenceWarning message\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('lasso',\n",
       "                                        Lasso(alpha=1.0, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=1000,\n",
       "                                              normalize=False, positive=False,\n",
       "                                              precompute=False,\n",
       "                                              random_state=123,\n",
       "                                              selection='cyclic', tol=0.0001,\n",
       "                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,\n",
       "                                          5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and tune model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted\n",
      "ridge has been fitted\n",
      "enet has been fitted\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary caller fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "#  Loop through model pipelines, tuning each ine and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv= 10, n_jobs= -1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name]\n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.3086275106063395\n",
      "ridge 0.3166111585985647\n",
      "enet 0.34287462885711767\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print( name, model.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('lasso',\n",
       "                                        Lasso(alpha=1.0, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=1000,\n",
       "                                              normalize=False, positive=False,\n",
       "                                              precompute=False,\n",
       "                                              random_state=123,\n",
       "                                              selection='cyclic', tol=0.0001,\n",
       "                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,\n",
       "                                          5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Display fitted random forest object\n",
    "    fitted_models['lasso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test set using fitted random forest\n",
    "pred = fitted_models['lasso'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.40888625065578077\n",
      "MAE: 85035.54222393448\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print R^2 and MAE\n",
    "print( 'R^2:', r2_score(y_test, pred))\n",
    "print( 'MAE:', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#555\">EXERCISES</span>\n",
    "\n",
    "Complete each of the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.1 - Coding Section Checkpoint</span>\n",
    "\n",
    "Before moving on, it's imperative that you've been following along the online Coding Section of this module. Those are core to each module and often contain **mission-critical code**, which means that the following modules REQUIRE you to have run that code.\n",
    "\n",
    "#### A.) First, confirm that you've successfully separated the data into a training set and a test set.\n",
    "* How many observations are in the training set?\n",
    "* How many observations are in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 observations in the training set, 373 observations on the test set\n"
     ]
    }
   ],
   "source": [
    "print( f'{X_train.shape[0]} observations in the training set, {X_test.shape[0]} observations on the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, display the Ridge regression pipeline object saved in the pipelines dictionary.\n",
    "* What steps are in the pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('elasticnet',\n",
       "                 ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                            l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                            positive=False, precompute=False, random_state=123,\n",
       "                            selection='cyclic', tol=0.0001,\n",
       "                            warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=123, solver='auto', tol=0.001))]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, display the <code>l1_ratio</code> hyperparameter values to try for your Elastic-Net algorithm.\n",
    "* **Tip:** Remember the naming convention within pipelines (need the named step first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('elasticnet',\n",
       "                 ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                            l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                            positive=False, precompute=False, random_state=123,\n",
       "                            selection='cyclic', tol=0.0001,\n",
       "                            warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['enet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.3, 0.5, 0.7, 0.9]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters['enet']['elasticnet__l1_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.2 - Sklearn's Standard Scaler</span>\n",
    "\n",
    "Whenever you preprocess your dataset, it's important to use the same **preprocessing parameters** on new data as you used on the training set. So if you standardize your dataset, you must also standardize the test set with the same means and standard deviations from the training set.\n",
    "\n",
    "#### A.) First, display the standardization parameters for the <code>beds</code> feature in the training set (<code>X_train</code>).\n",
    "* You'll need the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.434228187919463\n",
      "Standard Deviation: 1.0729140858452628\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean: {X_train.beds.mean()}')\n",
    "print(f'Standard Deviation: {X_train.beds.std()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0729140858452646\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TRAINING set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689    1.459\n",
       "1531    0.527\n",
       "668    -0.405\n",
       "1740    1.459\n",
       "117    -1.337\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal_5 = X_train.beds.iloc[:5]\n",
    "X_train_normal_5 = (X_train_normal_5 - X_train.beds.mean()) / X_train.beds.std()\n",
    "X_train_normal_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "1689    1.459\n",
    "1531    0.527\n",
    "668    -0.405\n",
    "1740    1.459\n",
    "117    -1.337\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TEST set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266   -1.337\n",
       "790   -0.405\n",
       "222   -1.337\n",
       "220   -1.337\n",
       "920   -0.405\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_normal_5 = (X_test.beds.iloc[:5])\n",
    "X_test_normal_5 = (X_test_normal_5 - X_train.beds.mean()) / X_train.beds.std()\n",
    "X_test_normal_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "266   -1.337\n",
    "790   -0.405\n",
    "222   -1.337\n",
    "220   -1.337\n",
    "920   -0.405\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Scikit-Learn's <code>StandardScaler()</code> class allows you to save those preprocessing parameters learned from the training set.\n",
    "1. First, initialize and instance of the scaler class.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "scaler = StandardScaler()\n",
    "</pre>\n",
    "\n",
    "2. Then, call the <code>.fit()</code> while passing in the **entire** training set (all of the features, not just beds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.) Now you can display the preprocessing parameters directly from the <code>scaler</code> object.\n",
    "* It will save the means from all features as an array in <code>.mean_</code>.\n",
    "* It will save the standard deviations from all features as an array in <code>.scale_</code>.\n",
    "* **Tip:** The <code>beds</code> feature should be the first one.\n",
    "* Check for yourself that the preprocessing parameters are the same as the ones you found in part (A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.434228187919463\n",
      "Standard deviation: 1.0725539871320342\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean: {scaler.mean_[0]}')\n",
    "print(f'Standard deviation: {scaler.scale_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0725539871320342\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.) Next, use the <code>scaler</code> object to <code>.transform()</code> your test set and save it as <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you use <code>scaler</code> to transform a dataset, it returns a NumPy array and NOT a Pandas DataFrame.\n",
    "\n",
    "#### G.) Confirm this for yourself. Display the class and shape of <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 39)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'numpy.ndarray'&gt;\n",
    "(373, 39)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H.) Finally, display the first 5 transformed values for the <code>beds</code> feature.\n",
    "* Because <code>X_test_new</code> is a NumPy array, you won't be able to just call <code>.beds</code> like with Pandas DataFrames. If you try that, you'll get the error:\n",
    "\n",
    "<pre>\n",
    "<span style=\"color:crimson\">AttributeError:</span> 'numpy.ndarray' object has no attribute 'beds'\n",
    "</pre>\n",
    "\n",
    "* Instead, you'll need to index the NumPy array to get the **first 5 rows** from the **first column**. (This is just meant as a refresher and a bit of practice.)\n",
    "* Confirm that the values are the same as the ones you found in part (C) manually. Note that the rounding/precision may be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.33720839 -0.40485439 -1.33720839 -1.33720839 -0.40485439]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_new[:5, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[-1.33720839 -0.40485439 -1.33720839 -1.33720839 -0.40485439]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.3 - Tree Pipelines</span>\n",
    "\n",
    "In the Coding Section, we created a pipeline dictionary with model pipelines for Lasso, Ridge, and Elastic-Net regressions. In this exercise, let's add pipelines for tree ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) Add pipelines for <code style=\"color:SteelBlue\">RandomForestRegressor</code> and <code style=\"color:SteelBlue\">GradientBoostingRegressor</code> to your pipeline dictionary.\n",
    "* Name them <code style=\"color:crimson\">'rf'</code> for random forest and <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n",
    "* Both pipelines should standardize the data first.\n",
    "* For both, set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> to ensure replicable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=123))\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Just as a quick sanity check, display the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('randomforestregressor',\n",
       "   RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                         max_features='auto', max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                         n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
       "                         warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'randomforestregressor': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                       n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
       "                       warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'randomforestregressor__bootstrap': True,\n",
       " 'randomforestregressor__criterion': 'mse',\n",
       " 'randomforestregressor__max_depth': None,\n",
       " 'randomforestregressor__max_features': 'auto',\n",
       " 'randomforestregressor__max_leaf_nodes': None,\n",
       " 'randomforestregressor__min_impurity_decrease': 0.0,\n",
       " 'randomforestregressor__min_impurity_split': None,\n",
       " 'randomforestregressor__min_samples_leaf': 1,\n",
       " 'randomforestregressor__min_samples_split': 2,\n",
       " 'randomforestregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'randomforestregressor__n_estimators': 'warn',\n",
       " 'randomforestregressor__n_jobs': None,\n",
       " 'randomforestregressor__oob_score': False,\n",
       " 'randomforestregressor__random_state': 123,\n",
       " 'randomforestregressor__verbose': 0,\n",
       " 'randomforestregressor__warm_start': False}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['rf'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) As another quick sanity check, display the class for the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pipelines['rf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's check that all of the model pipelines are of the correct type. For each item in your <code>pipelines</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lasso <class 'sklearn.pipeline.Pipeline'>\n",
      " ridge <class 'sklearn.pipeline.Pipeline'>\n",
      " enet <class 'sklearn.pipeline.Pipeline'>\n",
      " rf <class 'sklearn.pipeline.Pipeline'>\n",
      " gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "for name, pipline in pipelines.items():\n",
    "    print(f' {name} {type(pipline)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "ridge &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "enet &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "rf &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "gb &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.4 - Hyperparameter Grids</span>\n",
    "\n",
    "In the Coding Section, we declared hyperparameter grids for our regularized regression algorithms: Lasso, Ridge, and Elastic-Net. Next, let's do the same for our tree ensembles.\n",
    "\n",
    "\n",
    "#### Let's start by declaring the hyperparameter grid for our random forest.\n",
    "\n",
    "The first one we'll tune is <code style=\"color:steelblue; font-weight:bold\">n_estimators</code>.\n",
    "* This is the number of decision trees to include in the random forest.\n",
    "* Usually, more is better.\n",
    "* The default value is 10, which is usually too few.\n",
    "* Let's try 100 and 200.\n",
    "\n",
    "The second one we'll tune is <code style=\"color:steelblue; font-weight:bold\">max_features</code>.\n",
    "* This controls the number of features each tree is allowed to choose from.\n",
    "* It's what allows your random forest to perform feature selection.\n",
    "* The default value is <code style=\"color:crimson\">'auto'</code>, which sets <code style=\"color:steelblue\">max_features = n_features</code>.\n",
    "* Let's also try <code style=\"color:crimson\">'sqrt'</code>, which sets <code style=\"color:steelblue\">max_features = sqrt(n_features)</code>\n",
    "* And <code style=\"color:crimson\">0.33</code>, which sets <code style=\"color:steelblue\">max_features = 0.33 * n_features</code>\n",
    "\n",
    "#### A.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">RandomForestRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">rf_hyperparameters</code>\n",
    "\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__max_features'</span>: ['auto', 'sqrt', 0.33]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf__hyperparameters = {\n",
    "    'randomforestregressor__n_estimators' : [100, 200],\n",
    "    'randomforestregressor__max_features' : ['auto', 'sqrt', 0.33]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's declare settings to try for our boosted tree.\n",
    "\n",
    "#### B.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">GradientBoostingRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">gb_hyperparameters</code>.\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__learning_rate'</span>: [0.05, 0.1, 0.2]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__max_depth'</span>: [1, 3, 5]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb__hyperparameters = {\n",
    "    'gradientboostingregressor__n_estimators': [100, 200],\n",
    "    'gradientboostingregressor__learning_rate' : [0.05, 0.1, 0.2],\n",
    "    'gradientboostingregressor__max_depth' : [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lasso', 'ridge', 'enet', 'rf', 'gb'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our hyperparameters declared, let's store them in a dictionary for ease of access.\n",
    "\n",
    "#### C.) Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary.\n",
    "* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary.\n",
    "    * If you forgot what those keys were, you can insert a new code cell and call <code style=\"color:steelblue\">pipelines.keys()</code> for a reminder.\n",
    "* Set the values to the corresponding **hyperparameter grids** we've been declaring throughout this module.\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'rf'</span> : rf_hyperparameters</code>\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'lasso'</span> : lasso_hyperparameters</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'lasso' : lasso__hyperparameters,\n",
    "    'ridge' : ridge__hyperparameters,\n",
    "    'enet' :  enet__hyperparameters,\n",
    "    'rf' : rf__hyperparameters,\n",
    "    'gb' : gb__hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, run this code to check that <code style=\"color:steelblue\">hyperparameters</code> is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was found in hyperparameters, and it is a grid.\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was found in hyperparameters, and it is a grid.\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was found in hyperparameters, and it is a grid.\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "enet was found in hyperparameters, and it is a grid.\n",
    "gb was found in hyperparameters, and it is a grid.\n",
    "ridge was found in hyperparameters, and it is a grid.\n",
    "rf was found in hyperparameters, and it is a grid.\n",
    "lasso was found in hyperparameters, and it is a grid.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.5 - Model Dictionaries</span>\n",
    "\n",
    "Similar to how we created dictionaries for our pipelines and hyperparameter grids, we can do the same for our fitted models. Obviously, there are other valid ways to organize your code and models, but this is a simple and practical way that does the job. By the end of the script, you'll have various dictionary objects that can each be accessed by the same consistent keys.\n",
    "\n",
    "#### A.) Create a dictionary of models named <code style=\"color:SteelBlue\">fitted_models</code> to store models that have been tuned using cross-validation.\n",
    "* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n",
    "* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n",
    "* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n",
    "* **Tip:** We've started you off with some code.\n",
    "\n",
    "This step can take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted\n",
      "ridge has been fitted\n",
      "enet has been fitted\n",
      "rf has been fitted\n",
      "gb has been fitted\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary caller fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "#  Loop through model pipelines, tuning each ine and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv= 10, n_jobs= -1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name]\n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Check that the models are of the correct type. For each item in your <code>fitted_models</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "gb <class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(f'{name} {type(model)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "ridge &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "enet &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "rf &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "gb &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, run this code to check that the models have been fitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    try:\n",
    "        pred = model.predict(X_test)\n",
    "        print(name, 'has been fitted.')\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso has been fitted.\n",
    "ridge has been fitted.\n",
    "enet has been fitted.\n",
    "rf has been fitted.\n",
    "gb has been fitted.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.6 - Model Selection</span>\n",
    "\n",
    "In the Coding Section, we displayed performance metrics for a sample Lasso regression model. Now, let's do the same thing for all of our models, including our tree ensembles and then pick the final winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) First, display the cross-validated training performance for each model in <code style=\"color:SteelBlue\">fitted_models</code> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.3086275106063395\n",
      "ridge 0.3166111585985647\n",
      "enet 0.34287462885711767\n",
      "rf 0.4822444032459118\n",
      "gb 0.48813587008149295\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print( name, model.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso 0.30862751105084013\n",
    "ridge 0.3166111585985649\n",
    "enet 0.34285741369864786\n",
    "rf 0.4801823564169308\n",
    "gb 0.48778099198016756\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, use a <code style=\"color:SteelBlue\">for</code> loop, print the performance of each model in <code style=\"color:SteelBlue\">fitted_models</code> on the test set.\n",
    "* Print both <code style=\"color:SteelBlue\">r2_score</code> and <code style=\"color:SteelBlue\">mean_absolute_error</code>.\n",
    "* Those functions each take two arguments:\n",
    "    * The actual values for your target variable (<code style=\"color:SteelBlue\">y_test</code>)\n",
    "    * Predicted values for your target variable\n",
    "* Label the output with the name of the algorithm. For example:\n",
    "\n",
    "<pre style=\"color:crimson\">\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.409313458932\n",
    "MAE: 84963.5598922\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "------\n",
      "R^2: 0.40888625065578077\n",
      "MAE: 85035.54222393448\n",
      "ridge\n",
      "------\n",
      "R^2: 0.4093396476329718\n",
      "MAE: 84978.03564808935\n",
      "enet\n",
      "------\n",
      "R^2: 0.40524513729553746\n",
      "MAE: 86298.63725345599\n",
      "rf\n",
      "------\n",
      "R^2: 0.5650281163362425\n",
      "MAE: 68396.80973190349\n",
      "gb\n",
      "------\n",
      "R^2: 0.5263855696402104\n",
      "MAE: 71447.28100637316\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    pred = fitted_models[f'{name}'].predict(X_test)\n",
    "    print(name)\n",
    "    print('------')\n",
    "    print( 'R^2:', r2_score(y_test, pred))\n",
    "    print( 'MAE:', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "\n",
    "<pre>\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.4088862476281637\n",
    "MAE: 85035.54256465772\n",
    "\n",
    "ridge\n",
    "--------\n",
    "R^2: 0.4093396476329718\n",
    "MAE: 84978.03564808934\n",
    "\n",
    "enet\n",
    "--------\n",
    "R^2: 0.4038573361696519\n",
    "MAE: 86529.0068234889\n",
    "\n",
    "rf\n",
    "--------\n",
    "R^2: 0.5712128842598444\n",
    "MAE: 67885.87587131368\n",
    "\n",
    "gb\n",
    "--------\n",
    "R^2: 0.5270040007880257\n",
    "MAE: 71245.11216404787\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, ask yourself these questions to pick the winning model:\n",
    "* Which model had the highest $R^2$ on the test set?\n",
    "* Which model had the lowest mean absolute error?\n",
    "* Are these two models the same one?\n",
    "* Did it also have the best holdout $R^2$ score from cross-validation?\n",
    "* Does it satisfy our project's win condition? (**Tip:** In the event of ambiguous results based on the previous questions, THIS should be your final deciding factor on whether a model is \"good enough.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, plot the performance of the winning model on the test set.\n",
    "* Plot a scatterplot with predicted transaction price on the x-axis and actual transaction price on the y-axis.\n",
    "* This last visual check is a nice way to confirm our model's performance.\n",
    "* Are the points scattered around the 45 degree diagonal (what does the 45 degree diagonal line represent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f3b8406c240>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO29fZRc1XXg+6uubqoRaXUrjNwtBE8SRjoReCwn8CQUDVoOWEItIsnzyDhoZtnYsc3Lwh57xjIxBgdhsFlkQONhvRh4emYSmDUxZiA2YlAjy8IsPJogCM7IA24fIbA0oI/GMULqMXTTH/X+qHNbt2/dc++5VffWV+/fWlqqPnXrnHvqY+9z9t5n71yxWEQQBEEQwmir9w0IgiAIjYsoCUEQBMGKKAlBEATBiigJQRAEwYooCUEQBMFKe71vIG0mJyeLExOtGbGVz+do1bkFkbm2JjLXxqWjI/+PwNxge8spiYmJIm+//U69byMTenpmtezcgshcWxOZa+Myd27X4bB2MTcJgiAIVkRJCIIgCFaczE1KqX8LfAYoAv8T+BQwD3gYOBt4Efi41vo9pVQBeAi4GPg18Mda60Omn68CnwYmgC9orXeZ9nXAPUAe+I7W+k7TvihsjOqnLQiCILgQu5NQSs0HvgBcorX+ACVBfg3wF8C3tNYXACcoCX/M/ydM+7fMdSilLjSvuwhYB9yrlMorpfLAt4F+4EJgs7mWiDEEQRCEGuBqbmoHzlRKtQOzgGPA5cCj5vkHgY+ax5vM35jnr1BK5Uz7w1rrUa31L4GDwHLz76DW+jWzS3gY2GReYxtDEARBqAGx5iat9RGl1N3A/wLeBX5IyfTzttZ63Fz2BjDfPJ4PvG5eO66UOknJXDQfeM7Xtf81rwfaV5jX2Mawks/n6OmZFXdZU5LPt7Xs3ILIXJubHfuPsm33AY6dHGFedydb1ixh47JzWnKuNlplrrFKQik1h9IuYBHwNvBfKJmLGhIJgW0NZK7Ny8DgEHf88BVGxicBOHpyhJt/8BK/eWeUzSsXtdRco2i2z3Xu3K7Qdhdz00eAX2qtf6W1HgP+FlgF9BjzE8C5wBHz+AhwHoB5vpuSA3uqPfAaW/uvI8YQBMHCwOAQG7bvY/m2Z9mwfR8Dg0M1Hf/enxyaUhAeI+OT3PuTQzW9DyEdXJTE/wIuVUrNMn6CK4CfAz8G/shccy3wuHm8w/yNef5prXXRtF+jlCqYqKXFwPPAC8BipdQipdQZlJzbO8xrbGMIghCCt4o/PjxKETg+PModP3ylpopiaHg0UbvQ2MQqCa31PkrO459SCn9tA7YDXwG+pJQ6SMl/8IB5yQPA2ab9S8CNpp+XgUcoKZingM9prSeMz+HzwC5gEHjEXEvEGIIghNAIq/jerkKidqGxybVaZbqxsYliM9kBk9BsNs5qkLlWxvJtzxL2i84Bz29ZncoYcQR9EgCd7W3ctHax+CQamLlzu14ELgm2t1zuJkGYyfR2FTgeYtap5Sq+f2kvUNrVDA2P0ttV4PrLFk61C82FKAlBaCGuv2xh6Cr++ssW1vQ++pf2ilJoEURJCEILIat4IW1ESQhCiyGr+MZkYHCoKZW3KAlBEISMCTrzvdBkoOEVhaQKFwRByJhGCE2uFNlJCIIgZEyWBwyzNmPJTkIQBCFjsjpgWIsT9rKTEAQhdZrVSVspYfPdvHLR1PNZhSZHmbHSer9FSQiCkCpRTlq/4Gxm/Eqhq5Dn3bFJxiZLZ929+Z41q8DqBT1AdqHJtciTJUpCEIRUiVrdtoKSCCrBU6MTZdeMjE+ybfcBVn9m+VRbFqHJtThhLz4JQRBSpdWzwIYpwTCOnRzJ/F6uv2whne3TxXjaJ+xlJyEIQqo0Qv6oLHFVdvO6OzO+k9qcsBclIQhCqjRK/qissClBP53tbWxZs6Qm95P1CXtREoIgpEq98kcFI4xWnT+Hva+dSP0ewpRgew7OKrRzamR8aqyNy85pqlThNkRJCIKQOrXOHxUWUfXY/uNTz6eZBmOmJVEUJSEIQtPj4kxO8/zATEqiKNFNgiA0Pa7O5FaJsKolspMQhBYk6YnnZj8h7eJM9q4TkiFKQhBaAL+Qn93Zzm9Gxxk3xa7D7PEuJ4b91zc6Yc7kIK0UYVVLxNwkCE1OMMnbyZHTCsLDn5Y6eP2p0YkpBRF2fTPQv7SXm9Yupq+rQA7o6ypw9bK+aX/ftHZx0yi9RkJ2EoKQAbU037ieAPbs8UmvbxZmkjO5loiSEISUqbQKWaWKxVWYz+5sZ8P2fU62exD7vVBCzE2CkDKVVCGrpi6AqzA/NTLurCDEfi94xO4klFIK+J6v6XzgFuAh074QOAR8TGt9QimVA+4B1gPvAJ/UWv/U9HUt8DXTzze01g+a9ouBvwbOBHYCX9RaF5VSvx02RsWzFYQaYFvZRwnoauoCuDhtAYoRz4WdGI4bt9kjogQ3YpWE1loDHwJQSuWBI8D3gRuBPVrrO5VSN5q/vwL0A4vNvxXAfcAKI/C3ApdQ+r6+qJTaYYT+fcBngX2UlMQ6YCBiDEFoWKLCMQcGh0IFaTWZU4MngKOUQRh9FQj4Sk1q/tc3qoJp5HurB0nNTVcAr2qtDwObgAdN+4PAR83jTcBDWuui1vo5oEcpNQ+4EtittX7LKIbdwDrz3Gyt9XNa6yKlHYq/r7AxBKFhiTLT2ExO1Za37F/ayxPXreD5LavpS+BL6Osq8MR1KxILwUpMah61KLlZKY18b/UiqeP6GuC75nGv1vqYeXwc8L5l84HXfa95w7RFtb8R0h41hpV8PkdPzyynyTQb+Xxby84tSDPPdfPKRdyyU4c+NzQ8WjavfL6NG65U3Pz4S4yM+TKndpTak74PYX115HMUi0X8cr3S/r152Nqj+svn27h/7+FQBXP/3sOZFyXasf8o23Yf4NjJEeZ1d7JlzRI2Ljtn6vk0783/HY4bt5FxVhJKqTOAjcBXg88Z/0HSXW4iXMeYmCi2RObFMHp6ZrXs3II0+1z7ImoqBOfV0zOL1Qt6uGnN4jIzx+oFPYnfB1tfUJ6UrpL+vXmEzS+Xg+/+3S+tO5OenlnWYjzHTo5k+pkHTWRHT45w8w9e4jfvjE7db5r35n2HXcZtBObO7QptT7KT6Ad+qrX29l1DSql5WutjxmT0pmk/Apzne925pu0I8OFA+zOm/dyQ66PGEISGppKaCmnG+dv6Sqt/m7N8skisb6JeRYlcggOyuLdqghIagSQ+ic2cNjUB7ACuNY+vBR73tX9CKZVTSl0KnDQmo13AWqXUHKXUHGAtsMs8d0opdamJjPpEoK+wMQShoQk7AdxKJ369+bXlyp+L803UouRmGC7BAVncW7OXc3XaSSilzgLWAP+3r/lO4BGl1KeBw8DHTPtOSuGvBymFwH4KQGv9llLqduAFc91tWuu3zOPrOR0CO2D+RY0hCA1Pq58A7l/ay9YI30vU68BejyGr6CKXXUIWtSKavZxrrljM1JVQc8bGJorNbMuOotnt9EmQuTY+A4ND3DqgmQwRIV7UVJC4uQbt91BayaexC8uy7zBsPomsx62UuXO7XqR0RGEakpZDEITEeIIvTEHYzDMDg0Pcv/cwx06OWFfoWdrv61VRrtkr2clOoolo1hVnJchcGxtbDqi2HNzar8oEYNhqGqC7s50tl79/6vrl254NPQyYA57fsjqt268Jzfa5yk5CEITUsPkcisXwmhW5HKG7jpMj49OioZrdft+KSII/QaghA4NDbNi+j+XbnmXD9n1Ne5I37oR48ORymILw8EdD1SvySbAjOwlBqBG2fEdnzSqwekFPVf3W2t4ddw7EtWaFh7czaXb7fSsiSkKYsdRauNqcstt2H2D1Z5ZX1Ge1ifYqJU6YJz0DEAxDFaXQOIiSEGYk9RCuNsFpSwXhQjXRQNUqyShhHpW2IxgrI+akxkZ8EsKMpJosppVis+PP6+6suM9KT/Nmne3U5lu4++oPctt61bIn0VsR2UkIM5J6pEqw2fG3rFlScZ+VRgNlnU8oaI7qKuTJ5XJ8+dGfiZ+hyZCdhDAjqbZ+QyXY8jlVkzK60migWihJr8bF19cr3psocnJkXGo0NCGykxBmJJVkaU2DtJ2ylUYDZXkeIejreHdsoqmzoM50REkIM5JWCrWsRPFkpSTDAgJshO1apHRo4yFKQpix1DLUstGEX1ZKMsn5iOCupV7hvEI0oiQEIWMaVfhloSRdfRphu5ZmL87TqojjWhAyph7htvXC5tOYXcjHhr02e3GeVkV2EoKQMTNJ+Nl8HV++4gL6l/ZGZkaV5H5u1Np0KUpCaGgazZZfCbUSfo3wXlXj66hXxFkzUQ/TpSgJoWFpVFt+Umoh/OLeq1oqkEp9Ha0UcZYV9fDbiJIQGhbXH0QjrKCjqIXwi/N7xCnbRnkPJblfNPUwXYqSEBoWlx9EFruNLARm1sIv6r2KU7atsmObCdTDbyNKQmhYXH4QNgF464AGkgu5ZhWYUe9VnLKt1oSRVKk2yq6lGamH30ZCYIWGxSUvkU0AThapKD9QGuGq9ag+F/VexeWpqsaEEZZN9padmiv+cm/ovHfsP5pp9tlWx5b/S6KbhBmJiy3ftoKGyhx61dp8G7UIUNTqsxoThu2E9anRidB5b9t9QA7MVUmt/TaiJISGJu4HEbb99lNJhbRqbL71PDVse6/iFEg1Joyo9zds3rYCS614ZqRVECUhNDWeALp1QDNZLH8+qUOvWptvox6ci1K21URfRe3koHze87o7ORqiKOTAXOPipCSUUj3Ad4APAEXgTwANfA9YCBwCPqa1PqGUygH3AOuBd4BPaq1/avq5Fvia6fYbWusHTfvFwF8DZwI7gS9qrYtKqd8OG6OaCQuth4tJJWlflTpWbUKzCGzYvq+uTtosHMZxO7mg8N+yZgk3/+ClhjswJ850O66O63uAp7TWvwMsAwaBG4E9WuvFwB7zN0A/sNj8uw64D8AI/K3ACmA5sFUpNce85j7gs77XrTPttjEEYRppOvS8YjnPb1nNE9etSNRHmAPZo55O2qhypdWUMvXe9+7O8vVmmPDfuOycmjte48i6lGuzE7uTUEp1A6uBTwJord8D3lNKbQI+bC57EHgG+AqwCXhIa10EnlNK9Sil5plrd2ut3zL97gbWKaWeAWZrrZ8z7Q8BHwUGTF9hYwhCGY1wEMu/EwnbUdTLSRsXtVXNoUXvn+tqvBE+Jz+SfTYaF3PTIuBXwF8ppZYBLwJfBHq11sfMNccB792cD7zue/0bpi2q/Y2QdiLGsJLP5+jpmeUwreYjn29r2bkFaea5bl65iM0rF7Hkz58ixE3C0PDotLnVYq6V+Er897lj/1Hu2P0KI2O+qK3dr3DWrMJU+VVv3lE04uca9d5Uc6+NONdKcFES7cDvAf9aa71PKXUPAbOP8R+E/R5Sw3WMiYmiNctksxOVQbPVaIW5RkVK+edWi7nGRW3F3eddu/SUgvAYGZvkrl2a1Qt6nO+jET9X188pKY041yjmzu0KbXfxSbwBvKG13mf+fpSS0hgyZiTM/2+a548A5/lef65pi2o/N6SdiDEEoeFxOQwYRZqH8qLupZpDi8eHR2t6aDALqv2cWp1YJaG1Pg68rpRSpukK4OfADuBa03Yt8Lh5vAP4hFIqp5S6FDhpTEa7gLVKqTnGYb0W2GWeO6WUutRERn0i0FfYGILQ8FTjTE/bmRp1Ly73GRWi2uzO3nqcYm4mcsVivJVIKfUhSiGwZwCvAZ+ipGAeAf4P4DCl8NS3jKD/S0oRSu8An9Ja/73p50+Am0y339Ra/5Vpv4TTIbADlExbRaXU2WFjRN3r2NhEsZm2eElotu1rNcz0uW7Yvi/UBNLd2c6PPvf7tbq1KYInyW30dRV44roV1udn+ufayMyd2/UicEmw3UlJNBOiJFqDmT7X5dueDXV6A9y2XjmvctOM//f3Zbu3HPD8ltXWPmb659rI2JSEJPgThAYkyrzjmmwwC5OVd36kLyZpoNA6SFoOQXCg1idyr79sIbfs1KHPuab4qCb+3z/frkKeXC7HqZHxqbk3U6lROU1dHbKTEIQY7vzRAW7ZqWt6Ird/aS+zC/nQ51xX65XmkQruQE6NTnByZHza3IGmcPbKaerqkZ2EIEQwMDjEY/uPl7WnfSI3bLX75SsuqGq1XmlGW1v6bw9v7klTltQDOU1dPbKTEIQIouz/aWV2tRXigepW67Y8UqvOnxNy9Wlc5lXvrLauNGpW3mZCdhKCEMAligfSc9JGFeKpdrWeC5nBky+/ybL53dZ+49J/e9c0A/WoCd1qyE5CEHwEbdhRpOWkzaIQjzePd8fLZxFXjjUqky00roM6DDlNXT2ykxAEH3H2eI+rl/WlZtPOohBP3DyiFFCwpkZYdFOz2POrrQ8iiJIQhGnErd7bcjBZhO//7DiP7T9OX4VCx2/S6pnVQXsO/Iv+ale7cfPI5Ur3EFWtrlUEaSvNpR6IkhAEHzYbdndnO6Pjk1Orc69U6vHhUW5/6gB37znI8OiE00o1mOLixDtjdLTlmH1Gm3Mflc7DY7LIlHNcBKgQhfgkBMGHzYZdLBat5puxySKnRiec4/DDTEFjk0VmndFeUTU813kEGRmf5O49B6saR2h9ZCchODMTTq7abNhbLaefw4iLw3cNy6zm/Q7Ow+aEPzU6EWl2EgRREoITQROJP5a/1QRMmA3bVo7URpRPwCUsM4332z8PW1ZZgFsHdKJ+hZmFKAnBiUY8uVrLnU1YrqIooiKTVp0/p+wUd2d7G6vOn8OG7fsYGh4llzvt9/Co5P323iPxTwiVIkpCcKKWJ1cHBoe4f+9hjp0csQr/Wu9svD7v3nOQU6MTkddGRSYNDA7x5MvlBRb/6bzf4smX35yajy2Df5L327UGBNRf4QuNiziuBSdsK+O0T656gu3oyZFIR3DUziZL3puIPmLXliMydYbt/MKLb5xyEuZJ3m/XMx8ekqpCCEN2EoITWaaG9puNXM0sLjubtM1RLkK3WJy+kwneg83sE5xzGHE7lOBckwr93q7CjAhOEJIhSkJwIquTq0GTiKuZJc75W405yiYoXYSuf/ygaSrKL5CD0AiktlzpPYl6v21znd3ZzsmR8bLrZxfyvDdRLFP4q86fM2OCEwR3REkIzmRxctXVJBI0s8TtbFwd7UGFsOr8OdN8A35BGXdAzRs/iS/g9GtzFMmVzccl66ttrmfkc3S2t5X1+eUrLph6nV8RNmJwglB/REkINaGa1XmYmSVuZ2MT5scD5qjgyjmqdkRYVJKHPz3Hhu37EimI0hhFvr5+SUU7Ndt7ODw6wdfXK2ufwb5tZ0HEVzGzESUhZE6U6ce2Os8b30SUsIza2bSF+Da8do8kjt3jw6OhUUlXL+vjxo8smdZWiVDt7SpUvFOLMr0l6VPSagthSHSTkDlRZgxbGox/d/UHq0pRYXME+9uTCPO2HKEKZe9rJ8raooRqR1uO9tz0ts6O6gIA0kqHLWm1hTBkJyFkTlQkks1stHHZObz99jsVj9lnWRX3+QS4S3EdoMyu7ydsbraDd92d7Wy5/P3A9PnecKVi9YKe2PuwkVZQgaTVdmcmRYGJkhAyJ86MkYVD3CVk13bNVRe9j72vnShz6rqaYlyErf9xT8+sqhSi118a76Gk1Y5nJqWoAUcloZQ6BAwDE8C41voSpdRvA98DFgKHgI9prU8opXLAPcB64B3gk1rrn5p+rgW+Zrr9htb6QdN+MfDXwJnATuCLWuuibYxqJizUnizPWNhIIqhdV4RJ5uAJW2/FuXWnnjKvVVN7Is1V60xaDafJTIsCS7KT+AOt9T/6/r4R2KO1vlMpdaP5+ytAP7DY/FsB3AesMAJ/K3AJpZDwF5VSO4zQvw/4LLCPkpJYBwxEjCE0EZWYMXbsP8pdu3TV5hPba4IC8uvrVWT/lcwhjRVnVqvWmbYaTpNapqhpBKoxN20CPmwePwg8Q0mAbwIe0loXgeeUUj1KqXnm2t1a67cAlFK7gXVKqWeA2Vrr50z7Q8BHKSkJ2xhCCzMwOMQdu19hZCwbAeYqIMNW2k9ct8J5nDRWnFmtWmfaajhNZloUmKuSKAI/VEoVgf9Xa70d6NVaHzPPHwe8b9Z84HXfa98wbVHtb4S0EzGGlXw+R0/PLMdpNRf5fFtTzm3H/qPlQn/3K5w1q8DGZeeUXX//3sNT13qMjE9y/97DbF65qOr7uX/v4VAB6e8/6T2HEbXi9H+OUZ+rax9JyarfOJr1O+znhisVNz/+0rTvaGdHGzdcqZw/12bCVUn8M631EaXU+4DdSqlf+J80/gOH7DOV4zrGxESxaidgo5KGg7Me3LVLlwv9sUnu2qVDo3qOnRwJ7efYyZFE87fZ3F36T3rPYUStOP3ziPpcXftISlb9xtGs32E/qxf0cNOaxWXfrdULepw/10Zk7tyu0HancxJa6yPm/zeB7wPLgSFjRsL87500OgKc53v5uaYtqv3ckHYixhAsDAwOsWH7PpZve5YN2/dFltGsFUltuGlknPVMSsdNVTZ/NlmX/tOwO6dx7iCrswtyJqI6+pf28sR1K1IrN9vIxCoJpdRZSqku7zGwFngJ2AFcay67FnjcPN4BfEIplVNKXQqcNCajXcBapdQcpdQc088u89wppdSlJjLqE4G+wsYQQogSjPUkqdC//rKFdHZUJ8Du3nMw8QE+f/+2e+sq5J2VcP/SXm5au5i+rgI5Smc0XHIxpd1HLfsVWg8Xc1Mv8H2llHf932itn1JKvQA8opT6NHAY+Ji5fiel8NeDlEJgPwWgtX5LKXU78IK57jbPiQ1cz+kQ2AHzD+BOyxhCCI3qjEwaAtu/tJezZhUqjm4aGByyFgaKOsDn7z/snttz8O7YJKdGS7sJF4d6GucOXPtIGtIqZyIEF3JFW27mJmVsbKLYTHbAJDx7+O1Iwbl827Oh6aZzwPNbVtfsPsNIKsCqsedG1XPu6yo4RygF7/ndsYnQ1NtJ+gwjDdt1WOZZ1yyytaTZ7PTV0GxznTu360VKRxSmISeumwSXsNBGDs2r5ao1ym+QxGQVvOfl255NPF6tiNtFysE5oVJESTQJ9/7kUGhYqN+UVI+TzZWSttAaGBxi29Ovhq70Pbo726saI0oJ11oIu1a8GxoelYNzQlWIkmgSXKJt0krQlrXAS1toDQwOcftTBxiLqAHa2d42lVzPtc/ge2BTwrWu6Bb2/tno7So0rK9KaA5ESTQJrqakas06tVh1ViK0woS211dcJte+ChzfYe/BTWsXc9Pa8vj4Wgth1zoY3i5SigkJ1SBKokm4/rKF03wSkI0pqRYCL+kZhDChfftTBygWi4zHxF3kILFT2fYe3Dqgp+pN+3M91VoIu/Z71UXvo39pb6IMtoIQRIoONQn9S3v55qYPZB7XnsYhsrgDfV2FfOjrbEIrTGiPTcYriKg+o7DNdbJI6PmTNA7/JcG1X68gkhycE6pBdhJNxMZl51RVnMYFm1nLJtiDxJmrBgaHeHes3FTSnrNHHlW6Io/qMwqXYkT+3VWtAwZsRY2CeO9bs/iqhMZElIQwjesvW8htA7pslf7u2CQDg0OxQiHOXHXvTw6FOpjPKtgjj1wryPmZXcjz5SsuqEiI1UsIuxIcL2ep5+3fcTSDr0poTERJCNPoX9obGko6Nll08kvEmatsz58KjOevJ9FVyNPRlpumXDracmU+Cf/hMX+xn6RCu15CuNLT0raDdGnuZCRCauYiSkIoIyiwPVzMPnFRWF2FfGjKDL85K3hw8NToBO250jmHUyPjZdFNQcGaxqq3lkJ4x/6jVd1vLXYyM63QjnAaURJCGdWc3I6zz+dyudDX+dvDDg6OF+HMjjw/+tzvA9Er77RXvVkL4W27D1R9v1mfaG/k0/xCtoiSEMqoxhEbJ1BtuxR/e9yqNW6nkMWqN0shbKtvkfYqvRrHczOd5hfSRZSEUIYnOKb5JopFtj39qpON3yZQBwaHyOUgLKekf0Uat2qNOsewdad2GiN4X1mfMI/qf153J0dDFEUuV8oXlVbakkY3aQmNiSgJwcqoTxCPTBQZmSgpDE/A7D9ykr2vnQgVGkHBuOr8OTz58puhDuDgijTs4CDAqvPnANHnGCBcQdhWvVlH7bj0v2XNEm7+wUtlis+bTxr3lIYJTlKLz0xESQihxKV+GBmf5LH9x6f+9gsyoEww+q/105aj7FBg/9JefvGP7/A3z78+7donX36TZfO7nUNi28yOImrVm3XUjkv/G5edw2/eGY2MpvLvlCpZxYvjWagUURJCKJUID0/4eY9dKBbDV8fP6F9Z+3c9x1AsxtfRyFp4uvbvX6XbUpJXs7MQx7NQKZKWQwilUuExNDyaSMDaxoly5gZLb7aFB0w5zSHrlBqV9O8ytl8huyCpOYRKESUhhBImVFzo7So4C9goITWvu9PaP0wvRH9rv6pYAGYtPCvp3/W9T6KMpaa1UClibhJCCUazdBXy5HK5qcNsniM6aPJ5d2yCj6h/Evqcn7j03WHOXJtwrSbyJuy1q86fw7anX+UWk921mhQfldxbJSe+Xe9FlIKQFKlx3UQ0Ws3cgcEh7t5zsOwEdWd7G1dd9D52/+JXoc+5rGB7embx3b/7ZZnwtkVTZTkfKCULvKVfZSJk4z7XZqlf7UKjfYezpNnmKjWuhdTx8jwFGRmf5Ps/O86t/QqoPLbev/K980cHrNFUWYSqBhkvUrc8RXJGQagnoiSEaSQ5WDYwOGStKT1ZZKqam63oj+tYA4NDoSG0WYeqBkmaiTZNokxFksJbyBJREsIUSQ+WxUXXRAnxgcGhaSnJjw+PctvA6Qpv9+89zLGTI/R2FXjnvXBFBCXnbRpC0tUJ7JIuvZZICm8hayS6SZgi6uBXGC6C1XbN3XsOltWsGC/C7QOaO374CkdPjkxVgQvzEXh0FfLc8cNXOD48Glo1zhVXJ3CSsNNakPQzE4SkiJIQpkh6sKyacwg2wT9WdD+IB6XssWkIySzCTmuBnKQWssbZ3KSUygN/DxzRWv+hUmoR8DBwNvAi8HGt9XtKqQLwEHAx8Gvgj3J1DIMAAB/gSURBVLXWh0wfXwU+DUwAX9Ba7zLt64B7gDzwHa31naY9dIyqZy2E4noq1zPvxNnoO9vbWHX+HDZs35eJvfzqZX3WdB9BIek3Sc3ubKdYLDI8OjEtampkfJI2E27allLYaVZ487HFJjbKfQrNT5KdxBeBQd/ffwF8S2t9AXCCkvDH/H/CtH/LXIdS6kLgGuAiYB1wr1Iqb5TPt4F+4EJgs7k2agyhSgYGh9iwfR/Ltz3Lhu37uPNHB3h3rHx1Hzyb4NnAwxTE7EKe7s72qcNaV130Pp58+c1QU1B3ZzJ3WHdn+7SDYFcv62P3L8pTd3j4haT/novAyZFxTo1OTN3TY/uPT81nslia8z//YF/DnlCO+gygce5TaA2cfqlKqXOBq4BvAl9SSuWAy4F/aS55ELgVuA/YZB4DPAr8pbl+E/Cw1noU+KVS6iCw3Fx3UGv9mhnrYWCTUmowYgyhCsKcnWErcv8hsrjdw+xCnj2fXzWtbcP2faGmoLv3HOTLV1wwdVgtjs72NrZc/v7ISnFB/ELSJXIpeI97XzvBTWsXRzrE6xVVFDefM/KWPCWCUAGuy7n/APwZ0GX+Pht4W2vthZ28Acw3j+cDrwNorceVUifN9fOB53x9+l/zeqB9RcwYVvL5HD09sxyn1Vzk822pzO3+vYedhOZvdXaweeUitj7xMt99/nWraQNKPoZnD7/NxmXnsGP/UbbtPmBVKKdGJ/jFP77Dv1x+Xlmm186ONv6v353PMwd+xbG3R5jX3cmWNUvYuOycRPe/eeWiqceV2OeHhkfZvHLRtH787Nh/dFo68+PDo9yx+xXOmlWYdq8uJP1c4+ZzanSi4nvJmrS+w81Aq8w1Vkkopf4QeFNr/aJS6sPZ31J1TEwUm+qUYxLSOsFpS54Xdt13/+6XZYLcxg2P/Yz//sqbsSk5AP7m+de5bb3itvVqaofSloORsUmeHnyTG65UrF7QM3W9N++BwaHQAj1++roK094n19TifnoDfQS5a5cuq3cxMjbJXbv0tPt2Ienn6jKfSu8la7I6hdyIZ0Wa8MR1aLuLT2IVsFEpdYiSE/lySk7mHqWUp2TOBY6Yx0eA8wDM892UHNhT7YHX2Np/HTGGkICg/2G2oz+gt6uQKEposgiP7T/ubNrZ9vSr9C/tnYos8qfCvvnxl6aFsQ4MDvGRb//3WBNVmD0+abLCMD+M//0bGByqa1SR63yOD49O3W8rE/Q5VRoGLYQT+03TWn9Va32u1nohJcfz01rrfwX8GPgjc9m1wOPm8Q7zN+b5p7XWRdN+jVKqYKKWFgPPAy8Ai5VSi5RSZ5gxdpjX2MYQHAn7Af1mdJwOW35tgycosxR63mnt0Fj/sdNhrN4cbKe7Pbo720PzGQUzoHZ3tjO7kJ/mBLdlR7UJoK5CPvQeahFV5JoqHWaGwJSzItlSzYnrrwAPK6W+AfwD8IBpfwD4T8Yx/RYloY/W+mWl1CPAz4Fx4HNa6wkApdTngV2UQmD/o9b65ZgxBEfCfkDjRZh9Rhtnn9Feljzv+PAoOUo/slt2amrhAo1blbs4nm9bH518r9IMqDYBVGhvp7O9zSlLbRb45xPnyE8zfUkjImdFsiWRktBaPwM8Yx6/xunoJP81I8C/sLz+m5QipILtO4GdIe2hYzQ6adlHg/0E7fQur7fZrodHJ8qikYKpMgCrs/r/PG82L75xKvQsgSuzzWo87nxG3I+9r6uQmQC0jX1qZJyvG39Kve3g/gSAts+7lQWmVN3LFsndlDJp5dIJ6+fmx1/ipjVu6aG919sI+wHd+5NDZakyPMLqRbuEokbx5SsuAAgtR9rZcXpVHuWozXr1HiWA6lGfwbYA8f5t2L5vxgnM0O+PnBVJDVESKeNS+L7ifsbc+4kz0XhOTf/qN2q1aasXXfCZXDrzOUYm3LcW3rhhqbD9uyZbTeuwcxxJzjQExwzbCTSSAHJZgDTS/dYKSaWeLaIkUiYt+2i1/bhcFxQyUSv2sNQcQWGUREH0BfoLrsr94YNRQmBgcIgr/nLvtFxQwXmFCdfbBjS5XI4xYy+z7fgaSQC5LEAa6X5riVTdyw5REimTln200n7icvoE8QuZ6y9bWOaTAOhoy5WtRJOeYvbTnsO6so0zpwSvtZm7/POyOe8JVGW07fgaRQC5Lhwa5X6F1kCywKZMJYXvnfvpiO4nLqePDU/I9C/t5ZZ+NeVQhlK46J+vW1ImdJLsjPwRUrMLeWsZ0KTx7nGKyrvHJPfayA5e2wKhlf0NQv2RnUTKpLXdj7PTh1Hp6t4vZFxXoUlPMb8Q4s8I7hreeW88kT8nTqB780pyr40scGeiv0GoP6IkMiDJdj/K4Rplpw+j0lXwqvPnVPQaW5ruIL1dhbJ5rjp/zrT0HVFCPKqehUvUU5hwbc8xzScRfE0jMlP9DUJ9ESVRR9IuPVlJjiKAJ19+k2XzuxONGZWm249XU8Il66wN2+reFvXU3dk+LWusTbiGtTW6wBV/g1BrREnUEVu0yt17DlqFV9TOwyY044irRR0mXKNKivZ1FaZdX42TO2p1n2RlbROuInAFIRpREnXEepp3dGJKCPt3F2fNKoTuPPYfOTmVUiPNewnb6dz+1AGKxejYqSeuWzHt762OdSOgtAs4syPvvLp3WVk3YoZQQWgWREnUEVfzkLfSb2sLr+ecxHQTdS9BwnYAYzF5OMIqzrnOs6MtR7FYZGh4lHndnfzpqgVVC/O0TXqCMNOQENg6kiSF9dDwqHMdiKSEmXSi8j7ZyOegWCxOS6kN9rBgf/bVblN32isrevTkSOLspWEpvSVDqCBUh+wkMsDVvBFmU393bCI0JXZvV4G2tlxswZ2keBlfPaHpP6GctJ8chJrJXHwHG7bvK5t3knQmth2DzRdSaSSYmK6EmYYoiZRJat7wbOqe8AlTEN5K/6xZBW7+wUsVO4HD8IxH/vuMcjR7JiH/qezO9jbOyOfKnNl+IR/nO6g2DYltx9CWIzRTrWvhJT9iuhJmImJuqoAws4ZHJeaNqJPS/iI4G5edw01rF0cWmakGL7Iqysz05+uWcEu/KivSM2yJdnIV8tWeJraNM1kktMDSb0bHExfiEdOVMBORnURC4laTSVfEA4ND3DqgQ1e7fV2Fskghb8XqEuranoNNH+zj8Z8dt6YADxIX2ho8e+Bhq2XgKuSrPU1sc473mZPcY4F5jRdJnJm33sVtwg4k7n3tROp1S8SEJviRnURCbKvJWwc0A4NDiVbEnsKxBQzZwlK9e/AWyH1dBW5br7ht/fQV/qYP9rH3tRPOCiKKOIFdbc6qYEnOc7o7Q0uRVjJ+tbscj3rmTgrLa/XY/uNV13WW+tBCHLKTSEiUWeOOH77CVRe9b1q6CbALy7hDZkHhs2P/0Wmr7cni6b6DK/xqCwIF8QR2VJZWb06Vrkj9/cSlIAl7rW38anc5HvXMneRyIDG1uiUtXu5USIYoiYRExfyPjE+y97UT3LR2sZOwjFrJhgmfbbsPOP+gqznlHKQtVzoQt+3pV/nN6PjUziRoaotzTmdt1rCNn5ZwzzJ3Utx7k2YdEZfrGzkbrlBbREkkJC71xdDwaFnE0tadmnt/cqjshx+lcK666H1lwsd2TiLsB53mj9wzh4VFXrmuOusZGZSmcE8reaOf4A4x7L1xPZBYq7olwsxBfBIJ8Wzntggj78flYuuNyr6697UTZW3zujsjx4xrS4prFJWLQqp3ZFD/0l6euG4Fz29ZzRPXrchcMSWx9UftED1cDl6mVbcEKssMLLQmoiQqoH9pL7f2q0hHrYtQDFMEHmGCd8uaJc7O4STCoqMtx+xCfsrhfdt6xQtbVgcLt1lxUUg2RXJ8eLQuTtKoMOY0SKIUXXaIQcd+X1dh2ol1f6h0EvqX9nLVRe8ra3/y5TfFeS0AYm6qmDgThoutN2oF7he8frNFVyFPob2dUyPjsae5b3FIrNcX0YeLicN19RrVV60PpNXC9BWnFP3jzOvuDD1JH1S+WaUJD1usiPNa8BAlUQVRP1qbUCxSSkERt533BG9QoJ0anaCzvY2vrz9dAtSWzjuOsHMYHgODQ7w7Vh462tGW48yONoZHJxLZ9qN8OV4IMVQupJM4xWsR0ZNEKW5Zs6TsJH0tCyCJ81qIIlZJKKU6gWeBgrn+Ua31VqXUIuBh4GzgReDjWuv3lFIF4CHgYuDXwB9rrQ+Zvr4KfBqYAL6gtd5l2tcB9wB54Dta6ztNe+gYKc29aiqt7RBXdKcjN32nYjuX4RFcFbvsIMBud7aFz84u5PnyFRckFqS2RHt+vBBiSK4oku4MaiEU45SiXyFtXHYOv3lntG4H2sR5LUTh4pMYBS7XWi8DPgSsU0pdCvwF8C2t9QXACUrCH/P/CdP+LXMdSqkLgWuAi4B1wL1KqbxSKg98G+gHLgQ2m2uJGKPuxDkm/TbkpIwVmeon7lzG3XsOVhzqGmZm8E6Ah/U564z2igV4kpToSUnqFK/FoTjv87cR/FzTcKxX6mep9iCk0NrEKgmtdVFr/b/Nnx3mXxG4HHjUtD8IfNQ83mT+xjx/hVIqZ9of1lqPaq1/CRwElpt/B7XWr5ldwsPAJvMa2xh1x0Uw9S/trfiHdveeg2zYvo8o3/HI+GRkGo04goKqkhPgcSQ9r1HJGFH2/zChWSuh2L+017pISHuVXs3J6TCneCVOcKE1cfJJmNX+i8AFlFb9rwJva629wPk3gPnm8XzgdQCt9bhS6iQlc9F84Dlft/7XvB5oX2FeYxvDSj6fo6dnlsu0KmbH/qPWlfHQ8OjU+Dv2H+WO3clSbnv4q9Nlxbzuzmnv1f17D0cK9OD1LiQV+m05ePbw2/zzs3/LeSyb4zcHU5/T8eFR7tj9CmfNKrB55SLOmlVg2+4DHDs5wrzuTrasWcLGZeckutc4duw/ysh4+WfY2dHGDVeqqfnl821Vf2fDPruR8Unu33uYzSsXxb5+88pFTtdVSxpzbRZaZa5OSkJrPQF8SCnVA3wf+J1M76oKJiaKidI5JCWu1kJvV2Fq/Lt2aUbG0kvrHcaZHW0Ui1RkcvrTVQumvVdRRY0629tYubCHy/7dj6128zAfTZQDt6MtV1bpbqIIN//gJQBWL+hxnkeY/T+4IRoZm+SuXZrVC3pK/z6zfOqev/zoz7hrl071BHXYPXV3trPl8vezekHP1HufNAVJGLbP7tjJkUx/D0lJY67NQrPNde7crtD2ROcktNZvAz8GVgI9SilPyZwLHDGPjwDnAZjnuyk5sKfaA6+xtf86Yoy6EWU+8UwWnm24mprTrhQni9y0dnFo2dAorl7WNy06Ksq0lYOpnFQ2c4bN3LHq/DnWQ2DFYpGw83oj45Ns233AeS5h5hIb/p1NlsntbN+TMzvymZhx6pl8UGhtYpWEUmqu2UGglDoTWAMMUlIWf2QuuxZ43DzeYf7GPP+01rpo2q9RShVM1NJi4HngBWCxUmqRUuoMSs7tHeY1tjHqRpT5xHNUujpq02Bkokj/0l5+9Lnfn8oCG4V3WO7GjywB3BzLXYU8e187EemDsflovFxWYae3x4vlq32PpKVag45fF19AlqfAax1WKs5nIStclp/zgAeNX6INeERr/V+VUj8HHlZKfQP4B+ABc/0DwH9SSh0E3qIk9NFav6yUegT4OTAOfM6YsVBKfR7YRSkE9j9qrV82fX3FMkbNCJpQZne2h+YwgpLQeXdsItXKcUnwzm1E7WKOD4+y7elXp653cSwPj07EptuOEor9S3vZ6hiW62FLQeKKLanfqvPnsGH7PobM7iGMNAR5rcNKs0w+KMxsckXX3AtNwtjYRDEtO2CYXbk9B7lcuS09C7ojFJKHt0D3CwWXNOEdbTn+fN0Stu7UkRFUcNp8Yyvq88R1K6yKKe757s52Rscny4T5Nz/6AWefhI2wIj3BNO5hRB0yTDJ2mJIKixpqNtt1NchcG5e5c7teBC4JtsuJ6wjCVtnjRZh9Rhtnn9GeqUnJE1R3/ugA3//ZcWtYaliNaoBCe1ukMBybLHLvTw7Fpt7wmyyiVuZhfXS05aZea1vZb7n8/UD5CnjjsnOq/oEFT8Rv2L4vVkGkZaKxrey9+/C31SKqSBAqRZREBDazw/DoBHs+v4rl256NXYVXgt8B/uTLb1oVRJCR8Um2Pf1q2crcxvHh0ViHd3Dlm2Rl7t+lxplD0k6/HUaUGSkHqZtogkrKdjL8rFmFqndNgpAVoiQiiLMru+b498hhd9T68QSzy8o3SJx5Ksn1/prWkHxlHqwjXW2CumoT80XVwa7WvOSCzVG+bfcBVn9meebjC0IlSKrwCOIiRmzPR3HbehU7blwm2VoQZnYJpn1wUZBpzqHaaKR6RwDZ3oukkVxBsk57LsxsRElEEJeuwPa8LfwyZ8qAuhbziYqE6czn6Ah01NnexuxC3q3zEKLSMoSdKXAhzWieasNK651+wvZeVBPJleVZD0EAMTfFEmcisT0fFl3k+RaiAsr8PoLrL1tozejaM+sMrr9sYahjNCoLrM3kFWdyqaRmdnCVXm2N6zTCSrOqyeCC1Xm/ZknFfdYi7bkwsxElkQFBJ20uh5PzuaMtx5bL3z9NmNrw19IOEqUk8iEhvC4ml6h76esqTBVEyuVyoQWR0ij0YxOyzXJgzOa8ryaSKyqHmCCkgSiJKrGtjv0CfPm2Z62v9wSsfycQd8YBolfPfREOdX8Ib5IVfbVO3zRWvPU8MFbtLsgjjZ2Mdy9RJj9JxyGkhSiJKrjzRwemFQ/yCv7sP3JyKu0FuAlYlx++R9Tq2VZRzs+p0YnExYOqXcXH+ROCQviGK1VoWGhW5qIoJVCLcqdJ7tNlEdEsuyuh8RHHdYUMDA5Zq8s9tv/4NMdhXFSNa2GeOGer149LGGxS56bN6Qs4RdZEJaALc77e/PhLNXO+xjl/s8zxlBRX35D4I4S0kJ1ECC6mBS//kY3g+QCvLez0rcvuoa+rwE/+7A8ibddJnMuVODddD4d51/qJ2omECuGx2jlf40xhjVQD2mXMSqohCoINURIBXATfwOBQ7Go9rDxllICNwtWsk1RoVSvkkvgZovwJtuR/tRLCcUqgkWpAJ0mjIghpIEoigIvgczEzzI5Jd+G66u9L4CS1CZA2S3RVtUIu6Qrb5k+otxCOG7+RoqrC7sUjyXdFEFwRJRHARfC5rHBPjYwzMDhk/cG69HHbepWKc9krGJS2kEtLuIfed0fthHCcEmikNNyNdC+NRFrRZ0I5oiQC2ARfLseU0HfJ2VSEULOL92V2yeGU9EseJUCWze+eap/d2U6xWGTrTs29PzlU8Q8qrRV22H3bopuywEXw1vMQXpAs76UZhW0jRZ+1IlJPIkAwrNWPVw8A3M4y5IDnt6ye+juJHyLs/EEa+emT1Dlw7S8LodJsufiroVHmmvZ3I4ws5hpXy6ReNMrn6orUk3Bk72snrM95vgnvi5f0QJOrHyJLe3faaRwaaYUtVEezpvhopOizVkSUBNNXw3H7Ku+L5wnHgcEhbn/qQFmluvZc+YGmKIUSPHkd9aNMunp3mZ/8oIRmFbb1DnxodWa8kkhiAoLyL54nnLc9/epUWOzsQr7sRHPUwbAk2+Kk9lfX+ckPyo1mtNm70qzCtpGiz1qRGX/iOml2U9sX78yO/NRJ5LCUF1Fhs0m+zElP/7rMT35QbrR6Wu5619uolHqngG91ZvxOIslWOgdlEUGuK/uocZJ8mV2yfrqaz7Io2dnKNKvN3pVmDq8V31h2zHglkaQEqSdw/YrAVXBEJflzZcf+o9bnPJOAq3mp3pEfHs1kvmlWm30SRNgKQWa8ucm2xb56WV+kAPcUgavgSGMrv233AetzXj/NZF6qlfkmrfKeUUkKBaFVmfFKwmbPvPEjS0IFux9v9RtGLsc0oZSG3TSqFrJLXexGs9fWIrtqmoqoWW32glANM97cBPYtdtyq3DOPRJUqDfooqhHO87o7ORqiKPw7nmqLA9WSWphv0vQjNLPNXhAqJVZJKKXOAx4CeimZ5bdrre9RSv028D1gIXAI+JjW+oRSKgfcA6wH3gE+qbX+qenrWuBrputvaK0fNO0XA38NnAnsBL6otS7axqh61o5ECauOttw0ARFVqjQt5+aWNUu4+QcvRYb6VRMOmIZ/IEkftQi5TFsRic1emGm4mJvGgS1a6wuBS4HPKaUuBG4E9mitFwN7zN8A/cBi8+864D4AI/C3AiuA5cBWpdQc85r7gM/6XrfOtNvGqAlRwurMjrZp9SKeuG4Fz29ZjS3LSRqr443Lzok1WVVq1krDLJO0j1qYb8SPIAjVEbuT0FofA46Zx8NKqUFgPrAJ+LC57EHgGeArpv0hrXUReE4p1aOUmmeu3a21fgtAKbUbWKeUegaYrbV+zrQ/BHwUGIgYoyZcf9lCbrHUOhgeDS8RmvXq2GUlW8lqNw2zTNI+amG+kYNWglAdiXwSSqmFwO8C+4Beo0AAjlMyR0FJgbzue9kbpi2q/Y2QdiLGsJLP5+jpmeU4o2g2r1zEv//xq7z9bnmBoXndnaHj3HCl4ubHX2JkbHra6xuuVFXfVz7fltrcgkSZZVzHrKSPzSsXsXnlorL2tOa6eeUizppVYNvuAxw7OcK87k62rFnCxmXnVN13WmT5uTYaMtfmw1lJKKV+C3gM+Dda61NKqannjP8g03SyrmNMTBRTzbz4pT94f+hK9E9XLQgdZ/WCHm5as7hsdbx6QU/V95VlVsmoHZDrmGn04ZHmXFcv6GH1Z5ZPa2uk7JzNli20GmSujcvcuV2h7U4hsEqpDkoK4j9rrf/WNA8ZMxLm/zdN+xHgPN/LzzVtUe3nhrRHjVEzKrHx+30UT1y3oikcnWn4ByREVBBaD5fophzwADCotf73vqd2ANcCd5r/H/e1f14p9TAlJ/VJrfUxpdQu4A6fs3ot8FWt9VtKqVNKqUspmbE+Afw/MWPUlJkQ0ZKGf0BCRAWh9XAxN60CPg78T6XU/zBtN1ES3I8opT4NHAY+Zp7bSSn89SClENhPARhlcDvwgrnuNs+JDVzP6RDYAfOPiDGEDEhDGc4EhSoIMwmpTNdENJuNsxpkrq2JzLVxsVWmm/FpOQRBEAQ7oiQEQRAEK6IkBEEQBCuiJARBEAQrLee4Bn5FKRJKEARBcGcBMDfY2IpKQhAEQUgJMTcJgiAIVkRJCIIgCFZESQiCIAhWREkIgiAIVkRJCIIgCFZESQiCIAhWElWmEypDKdUJPAsUKL3nj2qttyqlFgEPA2cDLwIf11q/p5QqAA8BFwO/Bv5Ya33I9PVV4NPABPAFrfUu074OuAfIA9/RWt9p2kPHyHi+eeDvgSNa6z9s1XmacQ8Bw+Y+x7XWl5h67t8DFgKHgI9prU+YtPv3UMqS/A7wSa31T00/1wJfM91+Q2v9oGm/mNMZkncCXzQFuELHyHiuPcB3gA8AReBPAN1qc1Wlimrf8zWdD9xC6bvaUnN1QXYStWEUuFxrvQz4EKXa3pcCfwF8S2t9AXCCklDE/H/CtH/LXIdS6kLgGuAiYB1wr1Iqb4Tyt4F+4EJgs7mWiDGy5IvAoO/vVp2nxx9orT+ktfYyaN4I7NFaLwb2mL8x973Y/LsOuA/ACIatlOqvLAe2+uqu3Ad81ve6dTFjZMk9wFNa698BllH6jFturrrEh7TWH6K0gHkH+H7EfTTtXF0QJVEDtNZFrfX/Nn92mH9F4HLgUdP+IPBR83iT+Rvz/BVmtbIJeFhrPaq1/iWlmh3Lzb+DWuvXzOr5YWCTeY1tjExQSp0LXEVpxUnMPTTtPGPwzys434fM9+E5oMdUXLwS2K21fsusGndTWkjMA2ZrrZ/TWhcprWTD3rtafK7dwGpKBcjQWr+ntX67Feca4ArgVa314Yj7aJW5hiJKokaYlfD/oFSCdTfwKvC21nrcXPIGMN88ng+8DmCeP0nJjDLVHniNrf3siDGy4j8AfwZ4RcGj7qGZ5+lRBH6olHpRKXWdaevVWh8zj48DXhWmpPOabx4H26PGyIpFlFLe/JVS6h+UUt9RSp0VcR/NPFc/1wDfjbmPVplrKKIkaoTWesJsX8+ltCL+nTrfUuoopf4QeFNr/WK976WG/DOt9e9RMjl8Tim12v+kWSlmmvumFmNQ8qX9HnCf1vp3gd8QMIW00FwBUEqdAWwE/ks97qOWc41ClESNMVv0HwMrKW1LveCBc4Ej5vER4DwA83w3JcfuVHvgNbb2X0eMkQWrgI3GmfswJRPQPRH30KzznEJrfcT8/yYlu/VyYMiYFDD/v2kuTzqvI+ZxsJ2IMbLiDeANrfU+8/ejlJRGK87Vox/4qdZ6KOY+WmGuVkRJ1ACl1FwTGYJS6kxgDSWn34+BPzKXXQs8bh7vMH9jnn/arCp2ANcopQommmcx8DyluuGLlVKLzOrnGmCHeY1tjNTRWn9Va32u1nqhuYentdb/qtXm6aGUOksp1eU9BtYCLwXmFZzvJ5RSORO4cNKYFnYBa5VSc4xjcy2wyzx3Sil1qfG7fILw9y7z+WqtjwOvm8gfKNnqfx5xH007Vx+bOW1qirqPVpirFVEStWEe8GOl1M8oCbrdWuv/CnwF+JJS6iAlu/oD5voHgLNN+5cw23qt9cvAI5R+nE8BnzNmrHHg85S+lIPAI+ZaIsaoJa06z17gvyml9lNSYk9qrZ8C7gTWKKVeAT5i/oZSqONrlBzx/x9wPYDW+i3gdkrfjReA20wb5prvmNe8CgyYdtsYWfKvgf9svscfAu6IuI+mnqtR+muAv/U1t+Rc45BU4YIgCIIV2UkIgiAIVkRJCIIgCFZESQiCIAhWREkIgiAIVkRJCIIgCFZESQiCIAhWREkIgiAIVv5/ZKSZpe+A8lYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = fitted_models['rf'].predict(X_test)\n",
    "plt.scatter(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<img src=\"data:image/png;base64,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&#10;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.7 - Saving Your Model</span>\n",
    "\n",
    "Great job, you've created a pretty kick-ass model for real-estate valuation. Now it's time to save your hard work.\n",
    "\n",
    "#### A.) First, display the class of your winning \"model\" in the <code>fitted_models</code> dictionary object.\n",
    "* Remember, you can access it with its corresponding key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fitted_models['rf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.model_selection._search.GridSearchCV\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this is still the <code style=\"color:steelblue\">GridSearchCV</code> class. \n",
    "* You can actually directly save this object if you want, because it will use the winning model pipeline by default. \n",
    "* However, what we really care about is the actual winning model <code style=\"color:steelblue\">Pipeline</code>, right?\n",
    "\n",
    "#### B.) Confirm you can access the winning model pipeline. Display the class of the model pipeline.\n",
    "* **Tip:** You can use its <code style=\"color:steelblue\">best\\_estimator_</code> method to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fitted_models['rf'].best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.pipeline.Pipeline\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Display the winning pipeline object directly. What are the values of the winning values for our hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('randomforestregressor',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_...\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators='warn',\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=123,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'randomforestregressor__max_features': ['auto', 'sqrt',\n",
       "                                                                 0.33],\n",
       "                         'randomforestregressor__n_estimators': [100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['rf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winning values for our hyperparameters are:\n",
    "* <code style=\"color:steelblue\">n_estimators: <span style=\"color:crimson\">200</span></code>\n",
    "* <code style=\"color:steelblue\">max_features : <span style=\"color:crimson\">'auto'</span></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's save the winning <code style=\"color:steelblue\">Pipeline</code> object object. To do so, we'll import a helpful package called <code style=\"color:steelblue\">pickle</code>, which saves Python objects to disk.\n",
    "* First, <code>import pickle</code>.\n",
    "* Then, use the following syntax to \"dump\" your model into a pickle file.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(<strong>insert answer to previous question here</strong>, f)\n",
    "</pre>\n",
    "* **Note:** We'll show you in the next project how to take this a step further and use the pickled model for various use cases. For now, we don't want to spread ourselves too thin over too many topics, so let's just save that final model and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pricker.dump(fitted_models['rf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations... you've built and saved a successful model trained using machine learning!\n",
    "\n",
    "As a reminder, here are a few things you did in this module:\n",
    "* You split your dataset into separate training and test sets.\n",
    "* You set up preprocessing pipelines.\n",
    "* You tuned your models using cross-validation.\n",
    "* And you evaluated your models, selecting and saving the winner."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
